{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "african-diagram",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "basic-skating",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([b'batch_label', b'labels', b'data', b'filenames'])\n",
      "[ 59  43  50 ... 140  84  72]\n"
     ]
    }
   ],
   "source": [
    "with open('./cifar-10-batches-py/data_batch_1', 'rb') as fo:\n",
    "    d = pickle.load(fo, encoding='bytes')\n",
    "\n",
    "print(d.keys())\n",
    "data = d[b'data']\n",
    "labels = d[b'labels']\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "conscious-router",
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes 1D array of pixel data and converts to MxNx3 RGB format\n",
    "def reshape_img(pixeldata, m, n):\n",
    "    return np.rot90(pixeldata.reshape((m, n, 3), order='F'), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "unsigned-bloom",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data = [reshape_img(img, 32, 32) for img in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "growing-cricket",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_strs = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "def class_str(class_index):\n",
    "    return label_strs[class_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "literary-uruguay",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def display(image, index=-1):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    if index >= 0:\n",
    "        ax.set_title(class_str(labels[index]))\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "\n",
    "display(image_data[3], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "relevant-insulation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Adding this AFTER I've made the CNN forward prop: we need\n",
    "# to convert the classes given to us to one-hot-encoded vectors\n",
    "\n",
    "def one_hot(label, num_labels):\n",
    "    oh = np.zeros((num_labels))\n",
    "    oh[label] = 1\n",
    "    return oh\n",
    "\n",
    "print(one_hot(5, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "first-pipeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Great, so now we have our image data in a good format. \n",
    "\n",
    "# Let's first try to make sense of how a CNN is structured\n",
    "\n",
    "# We'll separate our data into training and testing groups later"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smooth-subscription",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network (CNN)\n",
    "We have our input image, structured in a MxNx3 format (3 dimensions for R, G, and B values) \n",
    "\n",
    "The input image generally feeds directly into a convolutional layer. A convolutional layer is made up of multiple filters, each of the same size. Filters have a size, let's say fxf, where each value is a weight. We can think of the filters as a sort of sliding window that goes across and down its input. The filters also have a \"stride,\" which is a measure of how quickly the filter \"slides\" across its input (ie. how many pixels does it jump)\n",
    "\n",
    "Let's say we have F filters. S = stride. The output layer will be of size ((InpSize - F)/S + 1). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "under-digest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay then, we'll attempt a convolutional layer.\n",
    "\n",
    "class ConvLayer:\n",
    "    \n",
    "    def __init__(self, num_filters, filter_size, stride=1):\n",
    "        self.num_filters = num_filters\n",
    "        self.filter_size = filter_size\n",
    "        self.stride = stride\n",
    "        \n",
    "        # initialize filters randomly (divide by filter_size^2 to normalize)\n",
    "        self.filters = np.random.randn(num_filters, filter_size, filter_size) / (filter_size**2)\n",
    "        # self.filters = [[[0.1, 0.1], [0.1, 0.1]], [[0.2, 0.2], [0.2, 0.2]]]\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    convolve takes a filter-sized patch of the image,\n",
    "    a filter itself, and performs the convolve operation,\n",
    "    returning a single sum\n",
    "    '''\n",
    "    def convolve(self, patch, f):\n",
    "        s = 0\n",
    "        height, width, depth = patch.shape\n",
    "        for d in range(depth):\n",
    "            for h in range(height):\n",
    "                for w in range(width):\n",
    "                    s += f[h][w]*patch[h][w][d]\n",
    "        return s\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    get_patch returns a filter-sized patch of the image,\n",
    "    given an i,j coordinate (upper-left pixel)\n",
    "    '''\n",
    "    def get_patch(self, image, i, j):\n",
    "        return image[i:(i+self.filter_size), j:(j+self.filter_size)]\n",
    "        \n",
    "    \n",
    "    '''\n",
    "    Forward propagation\n",
    "    '''\n",
    "    def forward_prop(self, image):\n",
    "        self.image = image\n",
    "        \n",
    "        height, width, d = image.shape\n",
    "        h_strides = int((width - self.filter_size) / self.stride + 1)\n",
    "        v_strides = int((height - self.filter_size) / self.stride + 1)\n",
    "        \n",
    "        self.out_size = (h_strides, v_strides, self.num_filters)\n",
    "        conv_out = np.zeros(self.out_size)\n",
    "        \n",
    "        for f, fltr in enumerate(self.filters):\n",
    "            for i in range(0, v_strides):\n",
    "                for j in range(0, h_strides):\n",
    "                    conv_out[i, j, f] = self.convolve(self.get_patch(image, i*self.stride, j*self.stride), fltr)\n",
    "        return conv_out\n",
    "    \n",
    "    '''\n",
    "    Backward propagation\n",
    "    dL_dout - will be the gradients from the next ConvLayer\n",
    "            (or the softmax layer if this is the last ConvLayer)\n",
    "    learning_rate - parameter for updating weights \n",
    "    '''\n",
    "    def backward_prop(self, dL_dout, learning_rate):\n",
    "        dL_dW_params = np.zeros(self.filters.shape)\n",
    "        \n",
    "        h, w, d = self.image.shape\n",
    "        h_strides, v_strides, nfilters = self.out_size   \n",
    "        \n",
    "        for i in range(h_strides):\n",
    "            for j in range(v_strides):\n",
    "                for f in range(nfilters):\n",
    "                    for layer in range(d):\n",
    "                        dL_dW_params[f] += self.get_patch(self.image, i, j)[:,:,layer] * dL_dout[i][j][f]\n",
    "\n",
    "        self.filters -= learning_rate * dL_dW_params\n",
    "        return dL_dW_params\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "provincial-duncan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3, 3)\n",
      "[[[ 4.62435078  0.72121803]\n",
      "  [ 6.94628208 -2.72895623]]\n",
      "\n",
      " [[ 4.62435078  0.72121803]\n",
      "  [ 6.94628208 -2.72895623]]]\n"
     ]
    }
   ],
   "source": [
    "# this is just a quick test of the forward prop math\n",
    "L = ConvLayer(2, 2)\n",
    "test_img = np.array([\n",
    "    [\n",
    "        [1, 2, 3],\n",
    "        [4, 5, 6],\n",
    "        [7, 8, 9]\n",
    "    ],\n",
    "    [\n",
    "        [1, 2, 3],\n",
    "        [4, 5, 6],\n",
    "        [7, 8, 9]\n",
    "    ],\n",
    "    [\n",
    "        [1, 2, 3],\n",
    "        [4, 5, 6],\n",
    "        [7, 8, 9]\n",
    "    ],\n",
    "])\n",
    "print(test_img.shape)\n",
    "print(L.forward_prop(test_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "motivated-landing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29, 29, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f690f3068e0>"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "L = ConvLayer(10, 4)\n",
    "conv_out = L.forward_prop(image_data[3])\n",
    "print(conv_out.shape)\n",
    "\n",
    "# output of a single conv layer (one slice)\n",
    "plt.imshow(conv_out[:,:,9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "acoustic-ultimate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 4. 7. 2. 5. 8. 3. 6. 9.]\n",
      "[1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "# At the end of our sequence of ConvLayers, we'll need to flatten\n",
    "# whatever output we get, in order to be fed into a softmax layer\n",
    "\n",
    "# It doesn't *exactly* matter how we go about flattening this layer.\n",
    "# The model will learn the patterns regardless of this layer's ordering\n",
    "# (at least I think)\n",
    "\n",
    "# EDIT: I'm just going to include this in the Softmax layer\n",
    "# EDIT2: numpy has a built-in flatten function, I'll use that instead\n",
    "\n",
    "def flatten(conv_out):\n",
    "    height, width, depth = conv_out.shape\n",
    "    out = np.zeros((height*width*depth,))\n",
    "    i = 0\n",
    "    for d in range(depth):\n",
    "        for h in range(height):\n",
    "            for w in range(width):\n",
    "                out[i] = conv_out[h][w][d]\n",
    "                i += 1\n",
    "    \n",
    "    return out\n",
    "\n",
    "print(flatten(np.array([\n",
    "    [\n",
    "        [1,2,3],\n",
    "        [4,5,6],\n",
    "        [7,8,9]\n",
    "    ]\n",
    "])))\n",
    "\n",
    "print(np.array([\n",
    "    [\n",
    "        [1,2,3],\n",
    "        [4,5,6],\n",
    "        [7,8,9]\n",
    "    ]\n",
    "]).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "mediterranean-roots",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After the convolutional layer, we'll want to put our image thru\n",
    "# a pooling layer. \n",
    "\n",
    "class MaxPoolLayer:\n",
    "    \n",
    "    def __init__(self, filter_size):\n",
    "        self.filter_size = filter_size\n",
    "        \n",
    "    \n",
    "    '''\n",
    "    * used from ConvLayer *\n",
    "    get_patch returns a filter-sized patch of the image,\n",
    "    given an i,j coordinate (upper-left pixel)\n",
    "    '''\n",
    "    def get_patch(self, image, i, j):\n",
    "        return image[i:(i+self.filter_size), j:(j+self.filter_size)]\n",
    "    \n",
    "    \n",
    "    def forward_prop(self, image):\n",
    "        self.image = image\n",
    "        height, width, nfilters = image.shape\n",
    "        \n",
    "        self.out_size = (height // self.filter_size, width // self.filter_size, nfilters)\n",
    "        out = np.zeros(self.out_size)\n",
    "        \n",
    "        for i in range(self.out_size[0]):\n",
    "            for j in range(self.out_size[1]):\n",
    "                out[i][j] = np.amax(self.get_patch(image, i*self.filter_size, j*self.filter_size), axis=(0,1))\n",
    "                \n",
    "        return out\n",
    "    \n",
    "    def backward_prop(self, dL_dout, learning_rate):\n",
    "        dL_dMP = np.zeros(self.image.shape)\n",
    "        height, width, nfilters = self.out_size\n",
    "        \n",
    "        for i in range(height):\n",
    "            for j in range(width):\n",
    "                image_patch = self.get_patch(self.image, i*self.filter_size, j*self.filter_size)\n",
    "                max_val = np.amax(image_patch, axis=(0,1))\n",
    "                h, w, f = image_patch.shape\n",
    "                \n",
    "                # iterate over inp image and \n",
    "                for ip in range(h):\n",
    "                    for jp in range(w):\n",
    "                        for fp in range(f):\n",
    "                            if image_patch[ip][jp][fp] == max_val[fp]:\n",
    "                                dL_dMP[i*self.filter_size + ip][j*self.filter_size + jp][fp] = dL_dout[i, j, fp]\n",
    "                                \n",
    "        return dL_dMP\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "catholic-twenty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 15, 4)\n",
      "(7, 7, 4)\n"
     ]
    }
   ],
   "source": [
    "# Let's test out forward prop\n",
    "\n",
    "img = image_data[5]\n",
    "Conv = ConvLayer(4, 4, 2)\n",
    "MP = MaxPoolLayer(2)\n",
    "conv_out = Conv.forward_prop(img)\n",
    "mp_out = MP.forward_prop(conv_out)\n",
    "\n",
    "print(conv_out.shape)\n",
    "print(mp_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "velvet-decline",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now I guess we can start creating our softmax layer. \n",
    "\n",
    "# This layer takes a single-dimensional input, and gives an \n",
    "# output of size C, where C is # of classes we're training\n",
    "\n",
    "class SoftmaxLayer:\n",
    "    \n",
    "    '''\n",
    "    num_inputs - the total size of the output of the previous ConvLayer\n",
    "    num_classes - number of classes we are training to predict\n",
    "    '''\n",
    "    def __init__(self, num_inputs, num_classes):\n",
    "        \n",
    "        # initialize weights & biases\n",
    "        self.weights = np.random.randn(num_inputs, num_classes) / num_inputs\n",
    "        self.biases = np.zeros(num_classes)\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    Forward propagation, Softmax layer\n",
    "    \n",
    "    img - will be the \"box\" of z outputs from the last ConvLayer\n",
    "    '''\n",
    "    def forward_prop(self, img):\n",
    "        \n",
    "        # these will be used in backward propagation\n",
    "        self.orig_img_shape = img.shape\n",
    "        self.flattened = img.flatten()\n",
    "        \n",
    "        # this is our z values out of the FC layer\n",
    "        self.output = np.dot(self.flattened, self.weights) + self.biases\n",
    "        print('weights at FC layer: ', self.weights)\n",
    "        \n",
    "        # e^(z_i)\n",
    "        exp_out = np.exp(self.output)\n",
    "        \n",
    "         # this is our y_hat predictions\n",
    "        return exp_out / np.sum(exp_out, axis=0)\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    Backward propagation, Softmax layer\n",
    "    \n",
    "    dL_dout - will be given from our model's main function - it is\n",
    "    going to be the cross-entropy loss\n",
    "    \n",
    "    learning_rate - model's learning rate\n",
    "    '''\n",
    "    def backward_prop(self, dL_dout, learning_rate):\n",
    "        for i, grad in enumerate(dL_dout):\n",
    "            if grad == 0:\n",
    "                continue\n",
    "            \n",
    "            exp = np.exp(self.output)\n",
    "            S_total = np.sum(exp)\n",
    "            \n",
    "            # case 2: i != l\n",
    "            dy_dz = -exp[i] * exp / (S_total**2)\n",
    "            \n",
    "            # case 1: i == l (this is equiv. to y*(1-y))\n",
    "            dy_dz[i] = exp[i]*(S_total - exp[i]) / (S_total**2)\n",
    "            \n",
    "            # dz_dw, dz_db, dz_dinput\n",
    "            dz_dw = self.flattened\n",
    "            dz_db = 1\n",
    "            dz_dinput = self.weights\n",
    "            \n",
    "            # grad is dL_dy\n",
    "            # dL/dz = dL/dy * dy/dz\n",
    "            dL_dz = grad * dy_dz\n",
    "            \n",
    "            # loss wrt. weights, biases, input\n",
    "            dL_dW = np.dot(dz_dw[np.newaxis].T, dL_dz[np.newaxis])\n",
    "            dL_db = dL_dz * dz_db\n",
    "            dL_dinput = np.dot(dz_dinput, dL_dz)\n",
    "            \n",
    "            # update weights and biases\n",
    "            self.weights = self.weights - (learning_rate * dL_dW)\n",
    "            self.biases = self.biases - (learning_rate * dL_db)\n",
    "            \n",
    "            return dL_dinput.reshape(self.orig_img_shape)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "responsible-september",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights at FC layer:  [[-1.05325120e-03 -1.07922720e-03  7.02093039e-04 ... -1.99389983e-03\n",
      "   2.81271563e-03  2.65365204e-05]\n",
      " [ 4.18169580e-04 -1.65011190e-03  1.18014226e-03 ...  8.39622602e-04\n",
      "  -1.65898035e-03 -1.55978072e-04]\n",
      " [-2.08837427e-03  2.30559608e-04  1.02723699e-03 ... -7.92848701e-04\n",
      "  -6.67843925e-04  1.07044534e-03]\n",
      " ...\n",
      " [ 1.76552817e-04 -1.37173080e-03 -6.73392962e-04 ... -2.69576899e-05\n",
      "  -7.48681766e-04  1.70139507e-04]\n",
      " [-2.94353535e-04 -5.63570860e-04  1.04538514e-04 ...  1.16461534e-03\n",
      "  -1.35985839e-03  2.36914062e-04]\n",
      " [-3.37059726e-04 -8.64856355e-04  1.91783161e-03 ... -3.08085474e-04\n",
      "  -3.46254705e-05  1.14438714e-03]]\n",
      "[3.78687738e-03 5.40165568e-03 2.43269007e-03 8.38830570e-06\n",
      " 1.36489901e-02 4.92509876e-02 1.27377362e-01 7.52091263e-01\n",
      " 8.56289026e-05 4.59161573e-02]\n"
     ]
    }
   ],
   "source": [
    "from math import prod\n",
    "sm = SoftmaxLayer(prod(conv_out.shape), 10)\n",
    "softmax_out = sm.forward_prop(conv_out)\n",
    "\n",
    "print(softmax_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "regulated-appliance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14, 14, 4)\n",
      "weights at FC layer:  [[-8.62362156e-04 -2.95377280e-03  3.10550766e-05 ...  3.05297520e-04\n",
      "   1.77731915e-03  8.68463525e-04]\n",
      " [-1.19893126e-03  1.07681010e-04  6.71452874e-04 ... -2.68097665e-04\n",
      "  -6.71370352e-04 -2.25809389e-04]\n",
      " [-6.86910617e-04  7.08813215e-04  3.66301270e-04 ...  1.30200698e-04\n",
      "   8.98149637e-04 -1.06507315e-03]\n",
      " ...\n",
      " [ 1.93160686e-05  3.94636198e-04 -2.88761908e-03 ...  2.19485918e-03\n",
      "   8.46884610e-04  1.50429019e-03]\n",
      " [-1.03632897e-04 -1.12836819e-03 -1.85546182e-03 ...  1.22972652e-03\n",
      "   1.42385982e-04  1.42251918e-03]\n",
      " [-5.44770090e-04 -2.36933939e-03  6.49693906e-04 ...  3.89019474e-04\n",
      "  -2.84408445e-04 -1.34084314e-03]]\n",
      "[3.23186297e-02 1.33933556e-01 5.10569468e-06 7.59760924e-02\n",
      " 9.28842207e-02 6.43614006e-02 4.32927662e-02 5.22308439e-01\n",
      " 3.36957877e-02 1.22400260e-03]\n"
     ]
    }
   ],
   "source": [
    "# Test run of one image forward prop thru whole model\n",
    "\n",
    "img = image_data[5]\n",
    "Conv1 = ConvLayer(num_filters=4, filter_size=4, stride=1)\n",
    "MP1 = MaxPoolLayer(2)\n",
    "\n",
    "# forward prop thru ConvLayers\n",
    "c1_out = Conv1.forward_prop(img)\n",
    "mp1_out = MP1.forward_prop(c1_out)\n",
    "\n",
    "print(mp1_out.shape)\n",
    "\n",
    "# softmax\n",
    "softmax = SoftmaxLayer(prod(mp1_out.shape), 10)\n",
    "softmax_out = softmax.forward_prop(mp1_out)\n",
    "\n",
    "print(softmax_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afraid-couple",
   "metadata": {},
   "source": [
    "### Calculating Cross-Entropy Loss\n",
    "Cross-entropy loss: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "another-peoples",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv backprop gradients shape:  (4, 4, 4)\n",
      "2.743241195764948 0\n"
     ]
    }
   ],
   "source": [
    "# Test run of one image thru backpropagation\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "l = 5\n",
    "oh_l = one_hot(labels[l], 10)\n",
    "cross_entropy_loss = -np.log(softmax_out[l])\n",
    "accuracy = 0\n",
    "if np.argmax(softmax_out) == l:\n",
    "    accuracy = 1\n",
    "    \n",
    "gradient = np.zeros(10)\n",
    "gradient[l] = -1/softmax_out[l]\n",
    "\n",
    "backprop = softmax.backward_prop(gradient, learning_rate)\n",
    "backprop = MP1.backward_prop(backprop, learning_rate)\n",
    "backprop = Conv1.backward_prop(backprop, learning_rate)\n",
    "print('conv backprop gradients shape: ', backprop.shape)\n",
    "\n",
    "print(cross_entropy_loss, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "productive-anthropology",
   "metadata": {},
   "source": [
    "### Now we have a 1-layer CNN\n",
    "Let's try to train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "brown-palestine",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights at FC layer:  [[-8.74013861e-04  1.69327560e-03 -8.84335788e-04 ...  1.19728204e-03\n",
      "  -6.79668293e-04  1.32695885e-04]\n",
      " [ 1.51890615e-03 -1.69643185e-03  1.07172519e-03 ... -1.08536080e-03\n",
      "   1.36338673e-03  7.19451576e-04]\n",
      " [ 6.19617335e-04 -1.10628798e-03 -6.45858076e-04 ...  1.15246054e-03\n",
      "  -9.85515770e-04 -4.42297131e-04]\n",
      " ...\n",
      " [-2.58157777e-04 -2.82072811e-03 -1.09964190e-05 ...  9.14528953e-04\n",
      "  -1.96960280e-03 -8.14536781e-04]\n",
      " [-3.06578577e-04 -1.10318950e-03  9.70848925e-05 ...  6.52769368e-04\n",
      "   2.16287257e-03 -1.17868223e-03]\n",
      " [ 2.98540479e-04  1.05306438e-03 -1.45530873e-04 ...  7.20888915e-04\n",
      "  -9.58220684e-04 -3.41078190e-04]]\n",
      "forward out:  [1.62330482e-03 6.17739141e-02 1.36888437e-02 9.05270569e-02\n",
      " 2.79815192e-02 6.23502311e-05 1.24622811e-03 1.08553225e-04\n",
      " 7.31804385e-01 7.11838447e-02] sum:  1.0\n",
      "after 0 steps: num_correct: 0, avg loss: 6.6876337993683155\n",
      "weights at FC layer:  [[-7.95381515e-04  4.68558346e-03 -2.21252750e-04 ...  1.20254032e-03\n",
      "   3.47686928e-02  3.58081766e-03]\n",
      " [ 2.43404167e-04 -5.02349126e-02 -9.68420125e-03 ... -1.17065584e-03\n",
      "  -5.73647498e-01 -5.52128254e-02]\n",
      " [-1.39595804e-03 -7.78078283e-02 -1.76426020e-02 ...  1.01767550e-03\n",
      "  -9.09629955e-01 -8.88276716e-02]\n",
      " ...\n",
      " [-1.44419584e-03 -4.79547120e-02 -1.00125004e-02 ...  8.35216519e-04\n",
      "  -5.36649132e-01 -5.28237148e-02]\n",
      " [-2.90233233e-03 -9.98830781e-02 -2.17921296e-02 ...  4.79186786e-04\n",
      "  -1.16803262e+00 -1.15005568e-01]\n",
      " [ 3.27824412e-04  2.16744730e-03  1.01411769e-04 ...  7.22847182e-04\n",
      "   1.22433113e-02  9.43057058e-04]]\n",
      "forward out:  [ 0. nan nan nan nan  0.  0.  0. nan nan] sum:  nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-424-91745d3b8370>:35: RuntimeWarning: overflow encountered in exp\n",
      "  exp_out = np.exp(self.output)\n",
      "<ipython-input-424-91745d3b8370>:38: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return exp_out / np.sum(exp_out, axis=0)\n",
      "<ipython-input-424-91745d3b8370>:54: RuntimeWarning: overflow encountered in exp\n",
      "  exp = np.exp(self.output)\n",
      "<ipython-input-424-91745d3b8370>:58: RuntimeWarning: invalid value encountered in multiply\n",
      "  dy_dz = -exp[i] * exp / (S_total**2)\n",
      "<ipython-input-424-91745d3b8370>:58: RuntimeWarning: invalid value encountered in true_divide\n",
      "  dy_dz = -exp[i] * exp / (S_total**2)\n",
      "<ipython-input-424-91745d3b8370>:61: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dy_dz[i] = exp[i]*(S_total - exp[i]) / (S_total**2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights at FC layer:  [[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "forward out:  [nan nan nan nan nan nan nan nan nan nan] sum:  nan\n",
      "weights at FC layer:  [[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "forward out:  [nan nan nan nan nan nan nan nan nan nan] sum:  nan\n",
      "weights at FC layer:  [[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "forward out:  [nan nan nan nan nan nan nan nan nan nan] sum:  nan\n",
      "weights at FC layer:  [[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "forward out:  [nan nan nan nan nan nan nan nan nan nan] sum:  nan\n",
      "weights at FC layer:  [[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "forward out:  [nan nan nan nan nan nan nan nan nan nan] sum:  nan\n",
      "weights at FC layer:  [[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "forward out:  [nan nan nan nan nan nan nan nan nan nan] sum:  nan\n",
      "weights at FC layer:  [[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "forward out:  [nan nan nan nan nan nan nan nan nan nan] sum:  nan\n",
      "weights at FC layer:  [[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "forward out:  [nan nan nan nan nan nan nan nan nan nan] sum:  nan\n",
      "weights at FC layer:  [[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "forward out:  [nan nan nan nan nan nan nan nan nan nan] sum:  nan\n",
      "weights at FC layer:  [[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "forward out:  [nan nan nan nan nan nan nan nan nan nan] sum:  nan\n",
      "weights at FC layer:  [[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "forward out:  [nan nan nan nan nan nan nan nan nan nan] sum:  nan\n",
      "weights at FC layer:  [[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "forward out:  [nan nan nan nan nan nan nan nan nan nan] sum:  nan\n",
      "weights at FC layer:  [[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "forward out:  [nan nan nan nan nan nan nan nan nan nan] sum:  nan\n",
      "weights at FC layer:  [[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "forward out:  [nan nan nan nan nan nan nan nan nan nan] sum:  nan\n",
      "weights at FC layer:  [[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "forward out:  [nan nan nan nan nan nan nan nan nan nan] sum:  nan\n",
      "weights at FC layer:  [[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "forward out:  [nan nan nan nan nan nan nan nan nan nan] sum:  nan\n",
      "weights at FC layer:  [[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "forward out:  [nan nan nan nan nan nan nan nan nan nan] sum:  nan\n",
      "weights at FC layer:  [[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "forward out:  [nan nan nan nan nan nan nan nan nan nan] sum:  nan\n",
      "weights at FC layer:  [[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "forward out:  [nan nan nan nan nan nan nan nan nan nan] sum:  nan\n",
      "weights at FC layer:  [[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "forward out:  [nan nan nan nan nan nan nan nan nan nan] sum:  nan\n",
      "weights at FC layer:  [[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "forward out:  [nan nan nan nan nan nan nan nan nan nan] sum:  nan\n",
      "weights at FC layer:  [[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "forward out:  [nan nan nan nan nan nan nan nan nan nan] sum:  nan\n",
      "weights at FC layer:  [[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "forward out:  [nan nan nan nan nan nan nan nan nan nan] sum:  nan\n",
      "weights at FC layer:  [[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "forward out:  [nan nan nan nan nan nan nan nan nan nan] sum:  nan\n",
      "weights at FC layer:  [[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "forward out:  [nan nan nan nan nan nan nan nan nan nan] sum:  nan\n",
      "weights at FC layer:  [[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "forward out:  [nan nan nan nan nan nan nan nan nan nan] sum:  nan\n",
      "weights at FC layer:  [[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "forward out:  [nan nan nan nan nan nan nan nan nan nan] sum:  nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-428-d701c55acf9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-428-d701c55acf9d>\u001b[0m in \u001b[0;36mtrain_image\u001b[0;34m(self, image, label)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m# Backward propagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward_prop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-428-d701c55acf9d>\u001b[0m in \u001b[0;36mbackward_prop\u001b[0;34m(self, initial_gradient)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mback_gradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward_prop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_gradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mback_gradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward_prop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mback_gradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-359-79915e96294e>\u001b[0m in \u001b[0;36mbackward_prop\u001b[0;34m(self, dL_dout, learning_rate)\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnfilters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                         \u001b[0mdL_dW_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_patch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdL_dout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilters\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdL_dW_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_images = image_data[:9000]\n",
    "test_images = image_data[9000:]\n",
    "\n",
    "train_labels = labels[:9000]\n",
    "test_labels = labels[9000:]\n",
    "\n",
    "class CNNModel:\n",
    "    def __init__(self, layers, num_classes, learning_rate=0.01):\n",
    "        assert len(layers) >= 1\n",
    "        self.layers = layers\n",
    "        self.num_classes = num_classes\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "    def forward_prop(self, image, label):\n",
    "        out_forward = self.layers[0].forward_prop(image)\n",
    "        for layer in self.layers[1:]:\n",
    "            out_forward = layer.forward_prop(out_forward)\n",
    "        \n",
    "        cross_entropy_loss = -np.log(out_forward[label])\n",
    "        accuracy = 0\n",
    "        if np.argmax(out_forward) == label:\n",
    "            accuracy = 1\n",
    "        \n",
    "        return out_forward, cross_entropy_loss, accuracy\n",
    "    \n",
    "    def backward_prop(self, initial_gradient):\n",
    "        back_gradient = self.layers[-1].backward_prop(initial_gradient, self.learning_rate)\n",
    "        for layer in reversed(self.layers[:-1]):\n",
    "            back_gradient = layer.backward_prop(back_gradient, self.learning_rate)\n",
    "    \n",
    "    def train_image(self, image, label):\n",
    "        \n",
    "        # Forward propagation\n",
    "        out_fw, loss, acc = self.forward_prop(image, label)\n",
    "        \n",
    "        print('forward out: ', out_fw, 'sum: ', sum(out_fw))\n",
    "        # calc initial gradient\n",
    "        gradient = np.zeros(self.num_classes)\n",
    "        gradient[label] = -1 / out_fw[label]\n",
    "        \n",
    "        # Backward propagation\n",
    "        self.backward_prop(gradient)\n",
    "        \n",
    "        return loss, acc\n",
    "    \n",
    "\n",
    "model_test = CNNModel(\n",
    "    layers=[\n",
    "        ConvLayer(4,4),\n",
    "        MaxPoolLayer(2),\n",
    "        SoftmaxLayer(784, 10)\n",
    "    ],\n",
    "    num_classes=10,\n",
    "    learning_rate=0.01\n",
    ")\n",
    "\n",
    "num_epochs = 1\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    num_correct = 0\n",
    "    loss = 0\n",
    "    \n",
    "    for i, (image, label) in enumerate(zip(train_images, train_labels)):\n",
    "        l, a = model_test.train_image(image, label)\n",
    "        \n",
    "        loss += l\n",
    "        num_correct += a\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print('after {steps} steps: num_correct: {acc}, avg loss: {loss}'.format(steps=i, acc=num_correct, loss=loss))\n",
    "            loss = 0\n",
    "            num_correct = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moved-details",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "announced-brain",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning",
   "language": "python",
   "name": "learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
