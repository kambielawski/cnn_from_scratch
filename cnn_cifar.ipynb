{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "african-diagram",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "basic-skating",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([b'batch_label', b'labels', b'data', b'filenames'])\n",
      "[ 59  43  50 ... 140  84  72]\n"
     ]
    }
   ],
   "source": [
    "with open('./cifar-10-batches-py/data_batch_1', 'rb') as fo:\n",
    "    d = pickle.load(fo, encoding='bytes')\n",
    "\n",
    "print(d.keys())\n",
    "data = d[b'data']\n",
    "labels = d[b'labels']\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "conscious-router",
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes 1D array of pixel data and converts to MxNx3 RGB format\n",
    "def reshape_img(pixeldata, m, n):\n",
    "    return np.rot90(pixeldata.reshape((m, n, 3), order='F'), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "unsigned-bloom",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data = [reshape_img(img, 32, 32) for img in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "growing-cricket",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_strs = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "def class_str(class_index):\n",
    "    return label_strs[class_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "literary-uruguay",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def display(image, index=-1):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    if index >= 0:\n",
    "        ax.set_title(class_str(labels[index]))\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "\n",
    "display(image_data[3], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "relevant-insulation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Adding this AFTER I've made the CNN forward prop: we need\n",
    "# to convert the classes given to us to one-hot-encoded vectors\n",
    "\n",
    "def one_hot(label, num_labels):\n",
    "    oh = np.zeros((num_labels))\n",
    "    oh[label] = 1\n",
    "    return oh\n",
    "\n",
    "print(one_hot(5, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "first-pipeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Great, so now we have our image data in a good format. \n",
    "\n",
    "# Let's first try to make sense of how a CNN is structured\n",
    "\n",
    "# We'll separate our data into training and testing groups later"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smooth-subscription",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network (CNN)\n",
    "We have our input image, structured in a MxNx3 format (3 dimensions for R, G, and B values) \n",
    "\n",
    "The input image generally feeds directly into a convolutional layer. A convolutional layer is made up of multiple filters, each of the same size. Filters have a size, let's say fxf, where each value is a weight. We can think of the filters as a sort of sliding window that goes across and down its input. The filters also have a \"stride,\" which is a measure of how quickly the filter \"slides\" across its input (ie. how many pixels does it jump)\n",
    "\n",
    "Let's say we have F filters. S = stride. The output layer will be of size ((InpSize - F)/S + 1). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "under-digest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay then, we'll attempt a convolutional layer.\n",
    "\n",
    "class ConvLayer:\n",
    "    \n",
    "    def __init__(self, num_filters, filter_size, inp_depth, stride=1):\n",
    "        self.num_filters = num_filters\n",
    "        self.filter_size = filter_size\n",
    "        self.stride = stride\n",
    "        \n",
    "        # initialize filters randomly (divide by filter_size^2 to normalize)\n",
    "        self.filters = np.random.randn(num_filters, filter_size, filter_size, inp_depth) / (filter_size**2)\n",
    "        # self.filters = [[[0.1, 0.1], [0.1, 0.1]], [[0.2, 0.2], [0.2, 0.2]]]\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    convolve takes a filter-sized patch of the image,\n",
    "    a filter itself, and performs the convolve operation,\n",
    "    returning a single sum\n",
    "    '''\n",
    "    def convolve(self, patch, f):\n",
    "        s = 0\n",
    "        height, width, depth = patch.shape\n",
    "        for d in range(depth):\n",
    "            for h in range(height):\n",
    "                for w in range(width):\n",
    "                    s += f[h][w]*patch[h][w][d]\n",
    "        return s\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    get_patch returns a filter-sized patch of the image,\n",
    "    given an i,j coordinate (upper-left pixel)\n",
    "    '''\n",
    "    def get_patch(self, image, i, j):\n",
    "        return image[i:(i+self.filter_size), j:(j+self.filter_size)]\n",
    "        \n",
    "    \n",
    "    '''\n",
    "    Forward propagation\n",
    "    '''\n",
    "    def forward_prop(self, image):\n",
    "        self.image = image\n",
    "        \n",
    "        inp_height, inp_width, d = image.shape\n",
    "        h_strides = int((inp_width - self.filter_size) / self.stride + 1)\n",
    "        v_strides = int((inp_height - self.filter_size) / self.stride + 1)\n",
    "        \n",
    "        self.out_size = (h_strides, v_strides, self.num_filters)\n",
    "        conv_out = np.zeros(self.out_size)\n",
    "        \n",
    "        for f, fltr in enumerate(self.filters):\n",
    "            for i in range(0, v_strides):\n",
    "                for j in range(0, h_strides):\n",
    "                    conv_out[i, j, f] = np.sum(self.get_patch(image, i*self.stride, j*self.stride) * fltr)\n",
    "                    # self.convolve(self.get_patch(image, i*self.stride, j*self.stride), fltr)\n",
    "        return conv_out\n",
    "    \n",
    "    '''\n",
    "    Backward propagation\n",
    "    dL_dout - will be the gradients from the next ConvLayer\n",
    "            (or the softmax layer if this is the last ConvLayer)\n",
    "    learning_rate - parameter for updating weights \n",
    "    '''\n",
    "    def backward_prop(self, dL_dout, learning_rate):\n",
    "        dL_dW_params = np.zeros(self.filters.shape)\n",
    "        \n",
    "        h, w, d = self.image.shape\n",
    "        h_strides, v_strides, nfilters = self.out_size   \n",
    "        \n",
    "        for i in range(h_strides):\n",
    "            for j in range(v_strides):\n",
    "                for f in range(nfilters):\n",
    "                    for layer in range(d):\n",
    "                        dL_dW_params[f] += self.get_patch(self.image, i*self.stride, j*self.stride) * dL_dout[i][j][f]\n",
    "\n",
    "        self.filters -= learning_rate * dL_dW_params\n",
    "        return dL_dW_params\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "provincial-duncan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-1.87524067 -3.31458369]\n",
      "  [-3.62844418 -5.63009687]]\n",
      "\n",
      " [[-1.87524067 -3.31458369]\n",
      "  [-3.62844418 -5.63009687]]]\n"
     ]
    }
   ],
   "source": [
    "# this is just a quick test of the forward prop math\n",
    "D = ConvLayer(num_filters=2, filter_size=2, inp_depth=3)\n",
    "test_img = np.array([\n",
    "    [\n",
    "        [1, 2, 3],\n",
    "        [4, 5, 6],\n",
    "        [7, 8, 9]\n",
    "    ],\n",
    "    [\n",
    "        [1, 2, 3],\n",
    "        [4, 5, 6],\n",
    "        [7, 8, 9]\n",
    "    ],\n",
    "    [\n",
    "        [1, 2, 3],\n",
    "        [4, 5, 6],\n",
    "        [7, 8, 9]\n",
    "    ],\n",
    "])\n",
    "print(D.forward_prop(test_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "motivated-landing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29, 29, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa76e5e0d30>"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "L = ConvLayer(num_filters=10, filter_size=4, inp_depth=3)\n",
    "conv_out = L.forward_prop(image_data[3])\n",
    "print(conv_out.shape)\n",
    "\n",
    "# output of a single conv layer (one slice)\n",
    "plt.imshow(conv_out[:,:,9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "acoustic-ultimate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 4. 7. 2. 5. 8. 3. 6. 9.]\n",
      "[1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "# At the end of our sequence of ConvLayers, we'll need to flatten\n",
    "# whatever output we get, in order to be fed into a softmax layer\n",
    "\n",
    "# It doesn't *exactly* matter how we go about flattening this layer.\n",
    "# The model will learn the patterns regardless of this layer's ordering\n",
    "# (at least I think)\n",
    "\n",
    "# EDIT: I'm just going to include this in the Softmax layer\n",
    "# EDIT2: numpy has a built-in flatten function, I'll use that instead\n",
    "\n",
    "def flatten(conv_out):\n",
    "    height, width, depth = conv_out.shape\n",
    "    out = np.zeros((height*width*depth,))\n",
    "    i = 0\n",
    "    for d in range(depth):\n",
    "        for h in range(height):\n",
    "            for w in range(width):\n",
    "                out[i] = conv_out[h][w][d]\n",
    "                i += 1\n",
    "    \n",
    "    return out\n",
    "\n",
    "print(flatten(np.array([\n",
    "    [\n",
    "        [1,2,3],\n",
    "        [4,5,6],\n",
    "        [7,8,9]\n",
    "    ]\n",
    "])))\n",
    "\n",
    "print(np.array([\n",
    "    [\n",
    "        [1,2,3],\n",
    "        [4,5,6],\n",
    "        [7,8,9]\n",
    "    ]\n",
    "]).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "mediterranean-roots",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After the convolutional layer, we'll want to put our image thru\n",
    "# a pooling layer. \n",
    "\n",
    "class MaxPoolLayer:\n",
    "    \n",
    "    def __init__(self, filter_size):\n",
    "        self.filter_size = filter_size\n",
    "        \n",
    "    \n",
    "    '''\n",
    "    * used from ConvLayer *\n",
    "    get_patch returns a filter-sized patch of the image,\n",
    "    given an i,j coordinate (upper-left pixel)\n",
    "    '''\n",
    "    def get_patch(self, image, i, j):\n",
    "        return image[i:(i+self.filter_size), j:(j+self.filter_size)]\n",
    "    \n",
    "    \n",
    "    def forward_prop(self, image):\n",
    "        self.image = image\n",
    "        height, width, nfilters = image.shape\n",
    "        \n",
    "        self.out_size = (height // self.filter_size, width // self.filter_size, nfilters)\n",
    "        out = np.zeros(self.out_size)\n",
    "        \n",
    "        for i in range(self.out_size[0]):\n",
    "            for j in range(self.out_size[1]):\n",
    "                out[i][j] = np.amax(self.get_patch(image, i*self.filter_size, j*self.filter_size), axis=(0,1))\n",
    "                \n",
    "        return out\n",
    "    \n",
    "    def backward_prop(self, dL_dout, learning_rate):\n",
    "        dL_dMP = np.zeros(self.image.shape)\n",
    "        height, width, nfilters = self.out_size\n",
    "        \n",
    "        for i in range(height):\n",
    "            for j in range(width):\n",
    "                image_patch = self.get_patch(self.image, i*self.filter_size, j*self.filter_size)\n",
    "                max_val = np.amax(image_patch, axis=(0,1))\n",
    "                h, w, f = image_patch.shape\n",
    "                \n",
    "                # iterate over inp image and \n",
    "                for ip in range(h):\n",
    "                    for jp in range(w):\n",
    "                        for fp in range(f):\n",
    "                            if image_patch[ip][jp][fp] == max_val[fp]:\n",
    "                                dL_dMP[i*self.filter_size + ip][j*self.filter_size + jp][fp] = dL_dout[i, j, fp]\n",
    "                                \n",
    "        return dL_dMP\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "catholic-twenty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29, 29, 10)\n",
      "(14, 14, 10)\n"
     ]
    }
   ],
   "source": [
    "# Let's test out forward prop\n",
    "\n",
    "img = image_data[5]\n",
    "M_P = MaxPoolLayer(2)\n",
    "mp_out = M_P.forward_prop(conv_out)\n",
    "\n",
    "print(conv_out.shape)\n",
    "print(mp_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "velvet-decline",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now I guess we can start creating our softmax layer. \n",
    "\n",
    "# This layer takes a single-dimensional input, and gives an \n",
    "# output of size C, where C is # of classes we're training\n",
    "\n",
    "class SoftmaxLayer:\n",
    "    \n",
    "    '''\n",
    "    num_inputs - the total size of the output of the previous ConvLayer\n",
    "    num_classes - number of classes we are training to predict\n",
    "    '''\n",
    "    def __init__(self, num_inputs, num_classes):\n",
    "        \n",
    "        # initialize weights & biases\n",
    "        self.weights = np.random.randn(num_inputs, num_classes) / num_inputs\n",
    "        self.biases = np.zeros(num_classes)\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    Forward propagation, Softmax layer\n",
    "    \n",
    "    img - will be the \"box\" of z outputs from the last ConvLayer\n",
    "    '''\n",
    "    def forward_prop(self, img):\n",
    "        \n",
    "        # these will be used in backward propagation\n",
    "        self.orig_img_shape = img.shape\n",
    "        flattened = img.flatten()\n",
    "        self.flattened = flattened\n",
    "        # print('flattened fc layer: ', flattened)\n",
    "        \n",
    "        # this is our z values out of the FC layer\n",
    "        out_val = np.dot(flattened, self.weights) + self.biases\n",
    "        self.output = out_val\n",
    "        \n",
    "        # e^(z_i)\n",
    "        exp_out = np.exp(self.output)\n",
    "        \n",
    "         # this is our y_hat predictions\n",
    "        return exp_out / np.sum(exp_out, axis=0)\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    Backward propagation, Softmax layer\n",
    "    \n",
    "    dL_dout - will be given from our model's main function - it is\n",
    "    going to be the cross-entropy loss\n",
    "    \n",
    "    learning_rate - model's learning rate\n",
    "    '''\n",
    "    def backward_prop(self, dL_dout, learning_rate):\n",
    "        for i, grad in enumerate(dL_dout):\n",
    "            if grad == 0:\n",
    "                continue\n",
    "            \n",
    "            exp = np.exp(self.output)\n",
    "            S_total = np.sum(exp)\n",
    "            \n",
    "            # case 2: i != l\n",
    "            dy_dz = -exp[i] * exp / (S_total**2)\n",
    "            \n",
    "            # case 1: i == l (this is equiv. to y*(1-y))\n",
    "            dy_dz[i] = exp[i]*(S_total - exp[i]) / (S_total**2)\n",
    "            \n",
    "            # dz_dw, dz_db, dz_dinput\n",
    "            dz_dw = self.flattened\n",
    "            dz_db = 1\n",
    "            dz_dinput = self.weights\n",
    "            \n",
    "            # grad is dL_dy\n",
    "            # dL/dz = dL/dy * dy/dz\n",
    "            dL_dz = grad * dy_dz\n",
    "            \n",
    "            # loss wrt. weights, biases, input\n",
    "            dL_dW = np.dot(dz_dw[np.newaxis].T, dL_dz[np.newaxis])\n",
    "            dL_db = dL_dz * dz_db\n",
    "            dL_dinput = np.dot(dz_dinput, dL_dz)\n",
    "            \n",
    "            # update weights and biases\n",
    "            self.weights = self.weights - (learning_rate * dL_dW)\n",
    "            self.biases = self.biases - (learning_rate * dL_db)\n",
    "            \n",
    "            return dL_dinput.reshape(self.orig_img_shape)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "responsible-september",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flattened:  186.4808540704952\n",
      "[0.20694686 0.06600033 0.02497304 0.21801773 0.08808075 0.0777726\n",
      " 0.08469937 0.15677403 0.04971776 0.02701752]\n"
     ]
    }
   ],
   "source": [
    "from math import prod\n",
    "sm = SoftmaxLayer(prod(mp_out.shape), 10)\n",
    "softmax_out = sm.forward_prop(mp_out)\n",
    "\n",
    "print(softmax_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "regulated-appliance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14, 14, 4)\n",
      "[1.52908715e-04 5.85639091e-03 1.21478269e-01 2.48066778e-02\n",
      " 1.31850018e-02 2.82051643e-03 8.06788190e-01 2.11445690e-02\n",
      " 2.22753211e-03 1.53994445e-03]\n"
     ]
    }
   ],
   "source": [
    "# Test run of one image forward prop thru whole model\n",
    "\n",
    "img = image_data[5]\n",
    "Conv1 = ConvLayer(num_filters=4, filter_size=4, inp_depth=3, stride=1)\n",
    "MP1 = MaxPoolLayer(2)\n",
    "\n",
    "# forward prop thru ConvLayers\n",
    "c1_out = Conv1.forward_prop(img)\n",
    "mp1_out = MP1.forward_prop(c1_out)\n",
    "\n",
    "print(mp1_out.shape)\n",
    "\n",
    "# softmax\n",
    "softmax = SoftmaxLayer(prod(mp1_out.shape), 10)\n",
    "softmax_out = softmax.forward_prop(mp1_out)\n",
    "\n",
    "print(softmax_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afraid-couple",
   "metadata": {},
   "source": [
    "### Calculating Cross-Entropy Loss\n",
    "Cross-entropy loss: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "another-peoples",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv backprop gradients shape:  (4, 4, 4, 3)\n",
      "5.870835281228023 0\n"
     ]
    }
   ],
   "source": [
    "# Test run of one image thru backpropagation\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "l = 5\n",
    "oh_l = one_hot(labels[l], 10)\n",
    "cross_entropy_loss = -np.log(softmax_out[l])\n",
    "accuracy = 0\n",
    "if np.argmax(softmax_out) == l:\n",
    "    accuracy = 1\n",
    "    \n",
    "gradient = np.zeros(10)\n",
    "gradient[l] = -1/softmax_out[l]\n",
    "\n",
    "backprop = softmax.backward_prop(gradient, learning_rate)\n",
    "backprop = MP1.backward_prop(backprop, learning_rate)\n",
    "backprop = Conv1.backward_prop(backprop, learning_rate)\n",
    "print('conv backprop gradients shape: ', backprop.shape)\n",
    "\n",
    "print(cross_entropy_loss, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "productive-anthropology",
   "metadata": {},
   "source": [
    "### Now we have a 1-layer CNN\n",
    "Let's try to train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "brown-palestine",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class CNNModel:\n",
    "    def __init__(self, layers, num_classes, learning_rate=0.01):\n",
    "        assert len(layers) >= 1\n",
    "        self.layers = layers\n",
    "        self.num_classes = num_classes\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "    def forward_prop(self, image, label):\n",
    "        out_forward = self.layers[0].forward_prop(image)\n",
    "        for layer in self.layers[1:]:\n",
    "            out_forward = layer.forward_prop(out_forward)\n",
    "        \n",
    "        cross_entropy_loss = -np.log(out_forward[label])\n",
    "        accuracy = 0\n",
    "        if np.argmax(out_forward) == label:\n",
    "            accuracy = 1\n",
    "        \n",
    "        return out_forward, cross_entropy_loss, accuracy\n",
    "    \n",
    "    def backward_prop(self, initial_gradient):\n",
    "        back_gradient = self.layers[-1].backward_prop(initial_gradient, self.learning_rate)\n",
    "        for layer in reversed(self.layers[:-1]):\n",
    "            back_gradient = layer.backward_prop(back_gradient, self.learning_rate)\n",
    "    \n",
    "    def train_image(self, image, label):\n",
    "        \n",
    "        # Forward propagation\n",
    "        out_fw, loss, acc = self.forward_prop(image, label)\n",
    "        \n",
    "        # calc initial gradient\n",
    "        gradient = np.zeros(self.num_classes)\n",
    "        gradient[label] = -1 / out_fw[label]\n",
    "        \n",
    "        # Backward propagation\n",
    "        self.backward_prop(gradient)\n",
    "        \n",
    "        return loss, acc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "visible-prefix",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 0 steps: num_correct: 0, avg loss: 5.078185651207864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-195-5f539de7717f>:37: RuntimeWarning: overflow encountered in exp\n",
      "  exp_out = np.exp(self.output)\n",
      "<ipython-input-195-5f539de7717f>:40: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return exp_out / np.sum(exp_out, axis=0)\n",
      "<ipython-input-195-5f539de7717f>:56: RuntimeWarning: overflow encountered in exp\n",
      "  exp = np.exp(self.output)\n",
      "<ipython-input-195-5f539de7717f>:60: RuntimeWarning: invalid value encountered in multiply\n",
      "  dy_dz = -exp[i] * exp / (S_total**2)\n",
      "<ipython-input-195-5f539de7717f>:60: RuntimeWarning: invalid value encountered in true_divide\n",
      "  dy_dz = -exp[i] * exp / (S_total**2)\n",
      "<ipython-input-195-5f539de7717f>:63: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dy_dz[i] = exp[i]*(S_total - exp[i]) / (S_total**2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 100 steps: num_correct: 6, avg loss: nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-203-b5da6e0c41ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-202-d810b3990fee>\u001b[0m in \u001b[0;36mtrain_image\u001b[0;34m(self, image, label)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# Forward propagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mout_fw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_prop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# calc initial gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-202-d810b3990fee>\u001b[0m in \u001b[0;36mforward_prop\u001b[0;34m(self, image, label)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward_prop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mout_forward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_prop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mout_forward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_prop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_forward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-56-bd619ef64b2a>\u001b[0m in \u001b[0;36mforward_prop\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_strides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_strides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m                     \u001b[0mconv_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_patch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfltr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m                     \u001b[0;31m# self.convolve(self.get_patch(image, i*self.stride, j*self.stride), fltr)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconv_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/dev/uciml_data_analysis/learning/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2245\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2247\u001b[0;31m     return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n\u001b[0m\u001b[1;32m   2248\u001b[0m                           initial=initial, where=where)\n\u001b[1;32m   2249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/uciml_data_analysis/learning/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_images = image_data[:9000]\n",
    "test_images = image_data[9000:]\n",
    "\n",
    "train_labels = labels[:9000]\n",
    "test_labels = labels[9000:]\n",
    "\n",
    "model_test = CNNModel(\n",
    "    layers=[\n",
    "        ConvLayer(num_filters=4, filter_size=4, inp_depth=3),\n",
    "        MaxPoolLayer(2),\n",
    "        SoftmaxLayer(num_inputs=784, num_classes=10)\n",
    "    ],\n",
    "    num_classes=10,\n",
    "    learning_rate=0.01\n",
    ")\n",
    "\n",
    "num_epochs = 1\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    num_correct = 0\n",
    "    loss = 0\n",
    "    \n",
    "    for i, (image, label) in enumerate(zip(train_images, train_labels)):\n",
    "        l, a = model_test.train_image(image, label)\n",
    "        \n",
    "        loss += l\n",
    "        num_correct += a\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print('after {steps} steps: num_correct: {acc}, avg loss: {loss}'.format(steps=i, acc=num_correct, loss=loss))\n",
    "            loss = 0\n",
    "            num_correct = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moved-details",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Something is going wrong, I think during backpropagation. I just want to isolate\n",
    "# one to two images and see what's going wrong. \n",
    "\n",
    "inp_img = image_data[7]\n",
    "# label = 7 (horse) \n",
    "label = labels[7]\n",
    "learning_rate=0.005\n",
    "\n",
    "Conv = ConvLayer(num_filters=4, filter_size=4, inp_depth=3)\n",
    "MaxPool = MaxPoolLayer(filter_size=2)\n",
    "Softmax = SoftmaxLayer(num_inputs=784, num_classes=10)\n",
    "\n",
    "conv_out = Conv.forward_prop(inp_img)\n",
    "mp_out = MaxPool.forward_prop(conv_out)\n",
    "sm_out = Softmax.forward_prop(mp_out)\n",
    "print(sm_out)\n",
    "\n",
    "cross_entropy_loss = -np.log(sm_out[label])\n",
    "print('cross entropy loss: ', cross_entropy_loss)\n",
    "accuracy = 1 if np.argmax(sm_out) == label else 0\n",
    "\n",
    "gradient = np.zeros(10)\n",
    "gradient[label] = -1/sm_out[label]\n",
    "\n",
    "print(gradient)\n",
    "\n",
    "grad_back = Softmax.backward_prop(gradient, learning_rate)\n",
    "grad_back = MaxPool.backward_prop(grad_back, learning_rate)\n",
    "grad_back = Conv.backward_prop(grad_back, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "announced-brain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv out:  [[[-353.91379478   42.55350862  -23.21699995 -225.23200375]\n",
      "  [-354.39322902   42.76497328  -22.63969572 -225.59421769]\n",
      "  [-354.36500209   44.04296923  -23.35545605 -225.56547197]\n",
      "  ...\n",
      "  [-351.2861697    45.09699051  -25.19435331 -222.73460167]\n",
      "  [-351.7685225    44.35101863  -24.58147915 -224.25589161]\n",
      "  [-355.53221181   44.25155398  -22.51832987 -227.63815806]]\n",
      "\n",
      " [[-354.43326373   43.34750646  -23.41532352 -224.85863172]\n",
      "  [-354.96700015   43.04785265  -22.86869483 -225.45275131]\n",
      "  [-356.10072554   43.57517065  -23.0751592  -226.38684996]\n",
      "  ...\n",
      "  [-348.93277833   42.19759941  -24.61361412 -222.10552078]\n",
      "  [-350.55029071   43.01977012  -22.55332703 -223.64148908]\n",
      "  [-354.69639655   43.54919183  -21.7684831  -227.11022429]]\n",
      "\n",
      " [[-353.6102218    43.10461234  -22.27533209 -225.28883409]\n",
      "  [-354.09819768   42.97663203  -22.3242413  -225.4300101 ]\n",
      "  [-355.21896014   43.0311486   -22.24342796 -226.4119752 ]\n",
      "  ...\n",
      "  [-348.72333874   41.83794872  -23.42422221 -221.44737352]\n",
      "  [-352.01633369   42.1825485   -21.47385802 -223.67785028]\n",
      "  [-353.78376623   42.52192417  -22.27171661 -225.64263909]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-180.08338263   18.79435749  -10.9419132  -118.64606056]\n",
      "  [-172.03623573   16.40991131   -9.12067364 -111.64936614]\n",
      "  [-160.70478937   12.11880732   -9.919454   -106.68473145]\n",
      "  ...\n",
      "  [-238.56783579   39.8270562    -2.47908229 -163.55170764]\n",
      "  [-264.99268455   45.14612068  -25.83940399 -177.47240234]\n",
      "  [-314.00379725   38.98221436  -21.79615411 -190.73503534]]\n",
      "\n",
      " [[-177.22318377   21.12567574   -9.83316626 -117.97691592]\n",
      "  [-170.13187325   18.83384905   -7.31591495 -111.34205421]\n",
      "  [-163.20260987   18.59078943   -6.43578179 -107.52315853]\n",
      "  ...\n",
      "  [-289.38602695   40.89851363   10.59782784 -205.98427781]\n",
      "  [-292.76574307   54.47485373   -7.58239607 -200.69469994]\n",
      "  [-330.27742879   50.95602369  -19.63442918 -207.01466933]]\n",
      "\n",
      " [[-178.46519415   20.35005541   -9.20815337 -118.9459572 ]\n",
      "  [-171.93411704   17.66278116   -8.37016401 -113.64236022]\n",
      "  [-167.96046044   27.55877242   -8.38370309 -109.4945187 ]\n",
      "  ...\n",
      "  [-352.56443179   28.6227939     8.35000387 -245.73759002]\n",
      "  [-345.00499257   46.75655435   -0.90263348 -229.39073325]\n",
      "  [-365.61536027   56.49329001  -14.63221776 -231.36495513]]]\n",
      "mp out:  [[[-353.91379478   43.34750646  -22.63969572 -224.85863172]\n",
      "  [-354.36500209   44.91801202  -23.0751592  -225.56547197]\n",
      "  [-356.37052049   45.38368225  -21.5898441  -228.51858211]\n",
      "  [-363.08186676   44.3178763   -22.07028695 -229.75745059]\n",
      "  [-362.51791508   44.50475209  -23.32120226 -229.67220935]\n",
      "  [-363.54594017   44.10767289  -22.92677615 -230.98493264]\n",
      "  [-363.28759302   43.94013305  -23.45892225 -230.88901302]\n",
      "  [-364.50992954   44.79369296  -23.76788288 -231.64004203]\n",
      "  [-368.38202858   42.33711231  -22.20169057 -230.21556194]\n",
      "  [-357.32890051   44.87106299  -21.44393684 -221.07575504]\n",
      "  [-348.53380066   43.31979034  -19.4477644  -223.05687864]\n",
      "  [-347.75483914   42.50871758  -20.97759242 -220.92805078]\n",
      "  [-349.46879899   45.07564457  -18.80176362 -220.76515514]\n",
      "  [-348.93277833   45.09699051  -22.55332703 -222.10552078]]\n",
      "\n",
      " [[-353.60840606   43.4428056   -21.86581386 -225.14794357]\n",
      "  [-354.71928539   43.03354241  -21.90779055 -226.34961663]\n",
      "  [-355.85275275   44.87037163  -21.96735904 -226.56703843]\n",
      "  [-357.68713991   45.0060134   -23.95108136 -227.58289548]\n",
      "  [-360.82475426   44.5430053   -22.89366893 -229.20870599]\n",
      "  [-363.2348206    44.1279916   -23.03259973 -231.09059518]\n",
      "  [-362.86026096   45.61693835  -23.69930436 -231.47326704]\n",
      "  [-363.29705167   45.67849282  -23.55983891 -230.75580947]\n",
      "  [-351.17740294   41.48434454  -25.00372432 -221.58894159]\n",
      "  [-341.96875146   46.95107757  -21.74492935 -212.47789939]\n",
      "  [-347.18249807   43.62383414  -20.84521518 -222.42882486]\n",
      "  [-347.30256192   44.13359281  -20.07012774 -220.21311543]\n",
      "  [-340.6965929    43.33232203  -21.68168676 -219.47354046]\n",
      "  [-339.51445272   44.65713847  -21.47385802 -218.760602  ]]\n",
      "\n",
      " [[-320.81290464   42.65088688  -23.50187549 -210.63867026]\n",
      "  [-315.60065579   42.70205553  -22.58099204 -207.53297385]\n",
      "  [-312.80998329   44.03728206  -26.45721984 -204.50715693]\n",
      "  [-316.98781686   43.8492142   -26.10633201 -206.73572537]\n",
      "  [-322.34604381   43.68624636  -25.9646746  -210.73229579]\n",
      "  [-322.28171013   41.90701574  -25.50420946 -212.73390943]\n",
      "  [-319.86404469   43.83824861  -25.80728907 -210.14335296]\n",
      "  [-331.39797519   48.01583946  -32.48462691 -212.25932001]\n",
      "  [-354.66739958   42.85802501  -19.30560031 -209.3161996 ]\n",
      "  [-343.17585199   45.10650672   -7.74485598 -212.92343542]\n",
      "  [-313.45451999   43.84472639  -13.6423013  -202.10574013]\n",
      "  [-286.48040883   42.93237924  -22.78620384 -186.54905871]\n",
      "  [-284.59263149   40.36928494  -25.17872852 -183.95385064]\n",
      "  [-280.49305013   38.99167612  -23.4735922  -178.55079745]]\n",
      "\n",
      " [[-268.94677488   37.96920677  -22.40867088 -167.51766866]\n",
      "  [-264.31415106   39.42662458  -22.03747245 -167.29822441]\n",
      "  [-264.23109012   38.09341475  -19.48527691 -170.47064709]\n",
      "  [-270.67712441   39.41974757  -19.66408848 -173.16906867]\n",
      "  [-274.99992165   38.90614659  -19.56744242 -174.85401703]\n",
      "  [-274.55425239   38.68273919  -21.62973977 -172.01138345]\n",
      "  [-272.66570751   45.37917159  -22.69402267 -172.79720458]\n",
      "  [-278.759581     57.87568377  -32.0700046  -181.1573817 ]\n",
      "  [-307.3863085    60.1792235   -21.96272645 -201.31882196]\n",
      "  [-311.27663773   39.87399225  -10.51782813 -194.70911769]\n",
      "  [-271.97974214   29.86034447  -11.97912637 -173.59125343]\n",
      "  [-243.92911011   38.26455082  -11.36004708 -163.50990928]\n",
      "  [-240.72799085   38.74961123  -14.07880173 -162.3842167 ]\n",
      "  [-237.49053529   40.11371413  -14.29346527 -162.97141554]]\n",
      "\n",
      " [[-237.55081871   34.73867031  -14.74362819 -160.7239223 ]\n",
      "  [-239.63625166   35.02066085  -13.83756105 -161.27208535]\n",
      "  [-242.50986165   31.59568588  -11.63409798 -163.47941571]\n",
      "  [-245.25784929   33.33127169  -13.42522881 -165.6912404 ]\n",
      "  [-247.92026098   34.03945245  -14.08105282 -166.07125717]\n",
      "  [-255.59747792   33.6194322   -15.39194153 -169.33617405]\n",
      "  [-256.25604441   31.65513833  -20.60501085 -167.90703593]\n",
      "  [-280.82330276   26.89215993   -1.73913322 -185.2209671 ]\n",
      "  [-297.86765709   42.51017396   -8.7906153  -183.52388588]\n",
      "  [-274.95574868   46.18226017  -14.14411308 -170.31257656]\n",
      "  [-255.68753086   33.06527308  -14.99960051 -163.70410181]\n",
      "  [-239.18878904   29.34066303  -13.41389067 -159.15799378]\n",
      "  [-236.07188869   29.40266488  -14.75193439 -159.04700241]\n",
      "  [-235.53525152   30.04403624  -14.4517082  -158.58517161]]\n",
      "\n",
      " [[-233.84977021   29.67383665  -14.61074418 -158.72247304]\n",
      "  [-236.57028075   31.46957584  -14.38684472 -160.85487157]\n",
      "  [-241.82973849   31.21993775  -14.19367925 -163.28268997]\n",
      "  [-243.93535792   30.27595229  -13.88264817 -164.25259422]\n",
      "  [-246.22343089   43.25752993  -14.29444579 -162.47753007]\n",
      "  [-254.29115485   57.22910266  -33.6059549  -166.7840339 ]\n",
      "  [-298.4452421    60.07436408   -6.507628   -189.50533817]\n",
      "  [-361.03679372   54.16821216   -4.40695509 -222.2174037 ]\n",
      "  [-339.46210791   41.93868316   -5.81720504 -208.20658993]\n",
      "  [-298.8981569    23.39102651   -0.61344995 -176.30811875]\n",
      "  [-252.73719838   31.78748373    4.06123452 -168.34430442]\n",
      "  [-235.39123169   30.48320023  -14.83311666 -157.712867  ]\n",
      "  [-232.11934776   28.88407152  -14.21434648 -157.05269989]\n",
      "  [-232.70146782   28.68188146  -13.80474054 -157.07280691]]\n",
      "\n",
      " [[-236.42094415   27.57645994  -20.98280033 -159.15677662]\n",
      "  [-249.58997193   21.29037345  -21.13126398 -161.31701528]\n",
      "  [-256.27705802   20.23037357  -16.37517315 -162.55435874]\n",
      "  [-251.92326295   25.6426384   -12.10318857 -164.48038593]\n",
      "  [-256.38039207   35.18152375  -16.25904473 -167.67206491]\n",
      "  [-276.79646323   41.33095517   -7.80586288 -181.20524344]\n",
      "  [-323.94350027   20.76316141  -16.55847122 -183.21654256]\n",
      "  [-295.27741205   66.01037698  -31.97849525 -165.09927452]\n",
      "  [-312.45865189   56.35340984  -31.37379775 -181.43350762]\n",
      "  [-295.12868889   47.96372977   -3.85056447 -182.86908444]\n",
      "  [-247.31582011   39.8650613    -4.06608148 -165.53793224]\n",
      "  [-231.48604811   27.3569082   -11.87972278 -156.92500725]\n",
      "  [-225.07433185   28.52090995  -14.58349371 -152.24292021]\n",
      "  [-226.7760312    28.46237325  -14.84489672 -152.3695176 ]]\n",
      "\n",
      " [[-225.54979005   76.74458301  -31.94864445 -161.12794082]\n",
      "  [-323.85216035   70.36493928  -10.79368836 -214.27730272]\n",
      "  [-367.28159353   47.12650074   -4.30860169 -231.42797244]\n",
      "  [-354.43592441   41.44896879   -3.84170907 -220.49765962]\n",
      "  [-330.23472344   29.99695105    5.74087121 -210.12766344]\n",
      "  [-310.87681072   29.0388824     5.03460966 -201.91261811]\n",
      "  [-268.46856658   28.60424978    9.38640598 -147.40845301]\n",
      "  [-218.17872035   42.1232968   -32.75078233 -140.43615608]\n",
      "  [-259.5359323    41.64071893  -26.5771258  -159.86286144]\n",
      "  [-287.8003653    41.42227893   -7.06620734 -172.00982264]\n",
      "  [-236.85606601   42.69691686   -5.26934191 -156.70740872]\n",
      "  [-229.39146195   27.79317493  -11.93272082 -154.36319116]\n",
      "  [-218.72217746   32.09974059  -12.53377503 -148.84753623]\n",
      "  [-221.81536944   34.03945033  -13.99536592 -150.67999636]]\n",
      "\n",
      " [[-243.22801504   30.99184506   -0.60987118 -161.95129746]\n",
      "  [-246.25002169   72.68430511  -38.91048777 -147.675936  ]\n",
      "  [-244.46066899   81.63750407  -65.85627855 -138.15393913]\n",
      "  [-311.64127133   76.24936123  -38.38904264 -186.40248347]\n",
      "  [-390.01449122   68.52949151  -15.00029071 -237.69841729]\n",
      "  [-381.67375863   58.15982021    1.60798987 -237.1997417 ]\n",
      "  [-305.65955903   55.05211949    8.68635734 -192.26306965]\n",
      "  [-237.83035265   41.19934806   13.51362932 -150.05478201]\n",
      "  [-254.13595472   53.73162158   -7.21261877 -162.10285607]\n",
      "  [-317.09802012   61.54620309  -19.69920632 -198.40531553]\n",
      "  [-262.59669353   22.76722946   21.85585243 -169.8105399 ]\n",
      "  [-230.04822149   27.74766143    4.97844502 -154.29733597]\n",
      "  [-219.66323011   26.88636243  -11.37568059 -148.72046247]\n",
      "  [-219.9660756    34.69939207  -12.65681101 -149.59588897]]\n",
      "\n",
      " [[-208.46909083   32.65163141    8.5768665  -125.91164965]\n",
      "  [-159.33686833    7.10464751   10.89448546 -109.69253791]\n",
      "  [-130.67811775   15.84359407    9.34124316  -73.16175906]\n",
      "  [-141.0298811    44.51347021  -44.50736308  -66.46478073]\n",
      "  [-178.97679705   64.97320913  -74.28179332  -85.34723633]\n",
      "  [-230.27330096   72.67259601  -63.5194952  -125.53767117]\n",
      "  [-307.27830834   84.81953641  -18.764229   -185.95586871]\n",
      "  [-359.08299168   73.80252191    4.13181904 -227.03322091]\n",
      "  [-354.98366169   41.04163632    2.58129326 -220.74897508]\n",
      "  [-361.49618733   60.70280719  -18.59196578 -222.0898524 ]\n",
      "  [-338.91823328   35.35666071    5.14597561 -212.96785393]\n",
      "  [-246.25346575   25.49842507   14.79141312 -162.39886128]\n",
      "  [-227.63773469   26.70336815  -11.76724817 -151.32423462]\n",
      "  [-228.94759612   21.44386322    1.68741255 -153.02765248]]\n",
      "\n",
      " [[-207.80828183   33.2287945   -14.07894464 -132.06034167]\n",
      "  [-150.53622752   30.83778685    7.97873812  -96.15684828]\n",
      "  [ -85.27477837    7.75111295   13.06818488  -66.41194802]\n",
      "  [ -66.16250546    7.93792718    5.19720683  -46.40223347]\n",
      "  [ -76.81140462    3.34144915    5.62933881  -53.5977209 ]\n",
      "  [-116.21147501   22.98315322   -5.86748935  -70.41866024]\n",
      "  [-169.3076771    71.51576724  -43.06656203  -92.35308398]\n",
      "  [-231.37792045   85.95462137  -63.48568626 -121.84386647]\n",
      "  [-335.75580185   68.78320948  -19.6538539  -200.16976462]\n",
      "  [-384.30118938   50.26457996  -26.62266086 -236.88536338]\n",
      "  [-357.30643994   39.98597205  -20.81544932 -207.09362517]\n",
      "  [-298.14542087   47.33183081  -28.79834336 -182.01650642]\n",
      "  [-303.67217647   34.37994238  -11.10856489 -184.84800689]\n",
      "  [-311.55738067   45.53653755   -1.69900642 -196.50049711]]\n",
      "\n",
      " [[-193.60958898   24.07369782  -14.96236628 -130.49545888]\n",
      "  [-177.25373073   33.46130581    0.46602333 -104.42523285]\n",
      "  [-102.25590015   14.99668882   11.91879086  -77.05088783]\n",
      "  [ -86.61465398   58.0727908     6.43515062  -61.32515308]\n",
      "  [-102.52630522   52.51918073    8.97562596  -69.0128375 ]\n",
      "  [-147.34294818   58.10291616   28.34288283  -90.18037659]\n",
      "  [-197.36004014   48.88238815   40.17369341 -118.44219585]\n",
      "  [-228.65451603   25.89101353   35.58702261 -132.24593381]\n",
      "  [-268.96558795   47.41060339  -12.80537846 -151.01242842]\n",
      "  [-304.10293531   60.58731674  -45.39046856 -163.73996163]\n",
      "  [-350.02551629   50.38854917  -14.15376035 -184.33131786]\n",
      "  [-300.01042377   21.86694778   -7.89775663 -180.19031073]\n",
      "  [-261.53650165   25.83173451  -20.9702414  -153.21687547]\n",
      "  [-267.80763869   75.07568059  -42.56948095 -161.36538   ]]\n",
      "\n",
      " [[-177.75101046   18.87968389  -11.46528469 -117.21898803]\n",
      "  [-154.31466402   22.86250212  -13.91059411  -96.67296493]\n",
      "  [-146.48232096   67.17987229   -5.8942012   -85.99830914]\n",
      "  [-146.82975394   70.67893694  -12.80205628 -110.35897378]\n",
      "  [-229.87338849   74.03554117   10.18766271 -153.10302555]\n",
      "  [-322.39450468   62.96479373   21.67764209 -231.27898513]\n",
      "  [-361.22900027   57.76230746   28.11550686 -256.88080233]\n",
      "  [-371.04429816   66.52921692   37.29508049 -235.28357484]\n",
      "  [-351.78050073   53.47223131   22.16353867 -217.55240719]\n",
      "  [-357.96855745   62.53052455   17.70447539 -218.32642833]\n",
      "  [-382.7031539    75.73367915    2.59006423 -220.10833895]\n",
      "  [-317.02234273   31.2763356    15.51240249 -196.86116288]\n",
      "  [-216.29871748   34.59691921   18.56270238 -118.74024413]\n",
      "  [-218.74392077   50.89589498  -21.50058945 -147.62043336]]\n",
      "\n",
      " [[-170.13187325   21.12567574   -7.31591495 -111.34205421]\n",
      "  [-150.78006957   30.87268753   -6.43578179  -98.81481236]\n",
      "  [-152.10085124   64.71757966  -24.35512434 -100.6255182 ]\n",
      "  [-231.42274578   52.70207378   -6.5657037  -166.39816415]\n",
      "  [-394.64164327   53.45274777   -2.64436485 -259.47415238]\n",
      "  [-447.13609176   56.68566521  -30.5202021  -273.77856968]\n",
      "  [-462.95564549   58.27266644  -32.83884989 -279.65041621]\n",
      "  [-453.02173865   56.24070676  -31.76911925 -277.96135576]\n",
      "  [-441.25101503   55.46859812  -28.31369592 -274.52812838]\n",
      "  [-443.84813458   50.50700588  -19.97286071 -276.07062566]\n",
      "  [-430.95052935   61.62277719  -24.19830838 -257.70625656]\n",
      "  [-374.54663521   68.11207815   -2.11631616 -229.26013929]\n",
      "  [-259.71774594   32.44144289   22.18530029 -171.90414019]\n",
      "  [-238.56783579   54.47485373   10.59782784 -163.55170764]]]\n",
      "output!!! [  14.92109621   -2.02493039  156.92219583   35.46506679    7.70585959\n",
      "   39.1429098    31.74458698 -279.60186773    9.06272117    5.31717291]\n",
      "sm out:  [2.13651532e-062 9.33555556e-070 1.00000000e+000 1.78582571e-053\n",
      " 1.57097243e-065 7.06489964e-052 4.32568826e-055 2.63031632e-190\n",
      " 6.10163265e-065 1.44136881e-066]\n",
      "exp:  [3.02099320e+006 1.32003031e-001 1.41398153e+068 2.52512457e+015\n",
      " 2.22132600e+003 9.98963761e+016 6.11644331e+013 3.71921869e-122\n",
      " 8.62759587e+003 2.03806887e+002] s total:  1.413981529740748e+68\n",
      "new weights after bprop:  [ 4.65419641e-03  1.81918389e-03  1.81737384e+00  1.03661014e-02\n",
      "  1.55048777e-03  1.19149921e-02  5.16493398e-03 -8.29723569e-02\n",
      " -1.76900829e+00  3.01453439e-03]\n"
     ]
    }
   ],
   "source": [
    "inp_img2 = image_data[8]\n",
    "# label = 8 (ship)\n",
    "label = labels[8]\n",
    "\n",
    "conv_out = Conv.forward_prop(inp_img2)\n",
    "print('conv out: ', conv_out)\n",
    "mp_out = MaxPool.forward_prop(conv_out)\n",
    "print('mp out: ', mp_out)\n",
    "sm_out = Softmax.forward_prop(mp_out)\n",
    "print('sm out: ', sm_out)\n",
    "\n",
    "cel = -np.log(sm_out[label])\n",
    "acc = 1 if np.argmax(sm_out) == label else 0\n",
    "\n",
    "grad = np.zeros(10)\n",
    "grad[label] = -1/sm_out[label]\n",
    "\n",
    "grad_back = Softmax.backward_prop(grad, learning_rate)\n",
    "grad_back = MaxPool.backward_prop(grad_back, learning_rate)\n",
    "grad_back = Conv.backward_prop(grad_back, learning_rate)\n",
    "# print(grad_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "egyptian-collection",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so clearly we're not even getting a good 2nd image result. 1st iteration goes fine but\n",
    "# we blow up after going thru forward prop on the 2nd image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "further-opera",
   "metadata": {},
   "source": [
    "###  I am getting super frustrated\n",
    "I am going to switch to a different dataset, I'll just go with the \"hello world\" of CNNs,\n",
    "the handwritten digits MNIST. It'll be one-dimensional, so I won't have to deal with \n",
    "RGB dimensions. I don't know if I jumped in too deep here or what, but I'm really\n",
    "annoyed with this. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certified-waters",
   "metadata": {},
   "source": [
    "# I might be an idiot\n",
    "I just realized after tweaking the MNIST dataset that I never normalized the CIFAR inputs. I've been feeding the raw RGB values into this thing. \n",
    "\n",
    "I'll be happy/sad if this is the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "developing-locator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "normalized_images = np.array(image_data) / 255.0\n",
    "\n",
    "train_images = normalized_images[:9000]\n",
    "test_images = normalized_images[9000:]\n",
    "\n",
    "print(normalized_images[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "complicated-genre",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 0 steps: num_correct: 1, avg loss: 2.2900776093244417\n",
      "after 100 steps: num_correct: 13, avg loss: 238.80101412867725\n",
      "after 200 steps: num_correct: 11, avg loss: 245.97544934867844\n",
      "after 300 steps: num_correct: 13, avg loss: 251.24336526429957\n",
      "after 400 steps: num_correct: 20, avg loss: 250.59443879186014\n",
      "after 500 steps: num_correct: 16, avg loss: 258.87914191411534\n",
      "after 600 steps: num_correct: 15, avg loss: 259.880196926331\n",
      "after 700 steps: num_correct: 15, avg loss: 256.5013440567586\n",
      "after 800 steps: num_correct: 13, avg loss: 317.7649872036314\n",
      "after 900 steps: num_correct: 20, avg loss: 284.3991043861602\n",
      "after 1000 steps: num_correct: 18, avg loss: 262.52079921145287\n",
      "after 1100 steps: num_correct: 15, avg loss: 341.2020152301997\n",
      "after 1200 steps: num_correct: 15, avg loss: 299.1895679531933\n",
      "after 1300 steps: num_correct: 15, avg loss: 314.2687417127545\n",
      "after 1400 steps: num_correct: 21, avg loss: 278.2016088842855\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-205-3b8a4dfc44d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-202-d810b3990fee>\u001b[0m in \u001b[0;36mtrain_image\u001b[0;34m(self, image, label)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m# Backward propagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward_prop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-202-d810b3990fee>\u001b[0m in \u001b[0;36mbackward_prop\u001b[0;34m(self, initial_gradient)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mback_gradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward_prop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_gradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mback_gradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward_prop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mback_gradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-56-bd619ef64b2a>\u001b[0m in \u001b[0;36mbackward_prop\u001b[0;34m(self, dL_dout, learning_rate)\u001b[0m\n\u001b[1;32m     72\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnfilters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m                         \u001b[0mdL_dW_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_patch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdL_dout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilters\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdL_dW_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-56-bd619ef64b2a>\u001b[0m in \u001b[0;36mget_patch\u001b[0;34m(self, image, i, j)\u001b[0m\n\u001b[1;32m     33\u001b[0m     '''\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_patch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = CNNModel(\n",
    "    layers=[\n",
    "        ConvLayer(num_filters=4, filter_size=4, inp_depth=3),\n",
    "        MaxPoolLayer(2),\n",
    "        SoftmaxLayer(num_inputs=784, num_classes=10)\n",
    "    ],\n",
    "    num_classes=10,\n",
    "    learning_rate=0.01\n",
    ")\n",
    "\n",
    "num_epochs = 1\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    num_correct = 0\n",
    "    loss = 0\n",
    "    \n",
    "    for i, (image, label) in enumerate(zip(train_images, train_labels)):\n",
    "        l, a = model.train_image(image, label)\n",
    "        \n",
    "        loss += l\n",
    "        num_correct += a\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print('after {steps} steps: num_correct: {acc}, avg loss: {loss}'.format(steps=i, acc=num_correct, loss=loss))\n",
    "            loss = 0\n",
    "            num_correct = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opponent-burton",
   "metadata": {},
   "source": [
    "# I can't believe myself\n",
    "\n",
    "Well, it seems to be working now. \n",
    "\n",
    "I spent quite a while combing through every line of code in this thing, and I never thought to check the input. It simply never occurred to me that I formatted my input incorrectly. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning",
   "language": "python",
   "name": "learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
