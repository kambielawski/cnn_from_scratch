{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "driven-tower",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "charming-window",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('mnist_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "innocent-literacy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "images = raw_data.iloc[:,1:].values\n",
    "images = images.astype(float)\n",
    "images = np.multiply(images, 1.0/255.0)\n",
    "size = int(np.sqrt(len(images[0])))\n",
    "images = [img.reshape((size, size)) for img in images]\n",
    "\n",
    "labels = raw_data.iloc[:,0].values\n",
    "print(labels[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "express-cheese",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f2daa2b1ee0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAANSUlEQVR4nO3db4wc9X3H8c/Hx9mOnaD4TH11jAOU4Ae0Uo/qMFX4UypSRFAqgxJZsZTElVAvD2IpSHkApa1ClQclURMatRHSBdw4VQpKlCD8gKQYCxWhRI4P4mIb00KoXewYn1MnsgnGf799cEN0wO3seWd2Z33f90ta3e58d3a+GvnjmZ3f7v4cEQIw981rugEAvUHYgSQIO5AEYQeSIOxAEhf0cmPzvSAWanEvNwmk8qZ+o5NxwjPVKoXd9i2Svi5pQNKDEXFf2fMXarGu8U1VNgmgxLbY2rLW8Wm87QFJ35D0UUlXSlpn+8pOXw9Ad1V5z75a0ssR8UpEnJT0iKQ19bQFoG5Vwr5C0qvTHu8vlr2N7THbE7YnTulEhc0BqKLrV+MjYjwiRiNidFALur05AC1UCfsBSSunPb64WAagD1UJ+3ZJV9i+zPZ8SZ+UtLmetgDUreOht4g4bXuDpH/X1NDbxojYXVtnAGpVaZw9Ih6X9HhNvQDoIj4uCyRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKVZnEF+tlvPnFNy9qXv/JA6bpfWvuZ0npM7OqopyZVCrvtvZKOSToj6XREjNbRFID61XFk/9OI+GUNrwOgi3jPDiRRNewh6Qnbz9oem+kJtsdsT9ieOKUTFTcHoFNVT+Ovi4gDtpdJ2mL7xYh4evoTImJc0rgkXeihqLg9AB2qdGSPiAPF30lJj0paXUdTAOrXcdhtL7b9vrfuS7pZ0vk3HgEkUeU0fljSo7bfep1/i4gf1dJVFxxfU37ScXzpQGl9aONP6mwHPTA52vpY9qW9f97DTvpDx2GPiFck/WGNvQDoIobegCQIO5AEYQeSIOxAEoQdSCLNV1x/cUP5/2uLLv91+QtsrK8X1GRe+XBpfPB4y9pNy14sXXerP9xRS/2MIzuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJJFmnP3vPva90vqX99zco05Ql4HLLymtv/gnrT8cMfLTT5Wu+4HtOzvqqZ9xZAeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJNKMsw/6dNMtoGYXPPhGx+se//mFNXZyfuDIDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJzJlx9rPXjZTWr1/4TG8aQc9cuvj/Ol535ZNnauzk/ND2yG57o+1J27umLRuyvcX2S8XfJd1tE0BVszmN/5akW96x7G5JWyPiCklbi8cA+ljbsEfE05KOvGPxGkmbivubJN1Wb1sA6tbpe/bhiDhY3H9N0nCrJ9oekzQmSQu1qMPNAaiq8tX4iAhJUVIfj4jRiBgd1IKqmwPQoU7Dfsj2ckkq/k7W1xKAbug07JslrS/ur5f0WD3tAOiWtu/ZbT8s6UZJF9neL+mLku6T9F3bd0jaJ2ltN5ucjX0fe09pfdkA1wvONxdc+sHS+ieGNnf82u/5n1+V1ufiKHzbsEfEuhalm2ruBUAX8XFZIAnCDiRB2IEkCDuQBGEHkpgzX3G94EPHKq3/5ovvr6cR1ObVf1xcWr92wdnS+kNHL25d/PXRTlo6r3FkB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEk5sw4e1XLJsrHbDGzgYuWltYPfXxVy9rQ2v2l6/7HqofabH1hafWBb9zWsrbs0I/bvPbcw5EdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5JgnL1wfKj8/73yb1ZXc/b6q0rrMeDS+qsfaT3TzskPnCpdd9788h9NfuL6fyqtD5a3ptfOtO7tb1+5vXTdI2fLP/uwaF5578PbWv/GQcspjOYwjuxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kMScGWc/8eZgaf1sm5HVf7nn/tL65g0j59rSrN219MHS+jyVD2Yfj5Mta784Uz4W/c+Hbyytf+TJO0vr7//Z/NL68icOtax5X/n32Q/vKZ+Ge3ig/DMEsX1naT2btkd22xttT9reNW3ZvbYP2N5R3G7tbpsAqprNafy3JN0yw/L7I2KkuD1eb1sA6tY27BHxtKQjPegFQBdVuUC3wfbzxWn+klZPsj1me8L2xCmdqLA5AFV0GvYHJF0uaUTSQUlfbfXEiBiPiNGIGB1U6y9FAOiujsIeEYci4kxEnJX0TUmr620LQN06Crvt5dMe3i5pV6vnAugPbcfZbT8s6UZJF9neL+mLkm60PaKprwXvlfTZ7rU4Ox/61M9K67//9xtK6yuvPlBnO+fkqcnWv60uSYd/WDLPuKSlu1uPN8//0fY2Wy8fq16liTbrlysb5T9w14dL1716wU9K64+8vqKDjvJqG/aIWDfD4na/3g+gz/BxWSAJwg4kQdiBJAg7kARhB5KYM19xbeeyvyofxulny/W/TbfQFYtuOFxp/b956uOl9VX6aaXXn2s4sgNJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEmnG2TH3XPJYxomXO8eRHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Lg++zoWwMuPxb9atVgaf13f1hnN+e/tkd22yttP2X7Bdu7bX++WD5ke4vtl4q/S7rfLoBOzeY0/rSkL0TElZL+WNLnbF8p6W5JWyPiCklbi8cA+lTbsEfEwYh4rrh/TNIeSSskrZG0qXjaJkm3dalHADU4p/fsti+VdJWkbZKGI+JgUXpN0nCLdcYkjUnSQi3quFEA1cz6arzt90r6vqQ7I+Lo9FpEhKQZf/0vIsYjYjQiRge1oFKzADo3q7DbHtRU0L8TET8oFh+yvbyoL5c02Z0WAdRhNlfjLekhSXsi4mvTSpslrS/ur5f0WP3tIbMzcbb0pnkqv+FtZvOe/VpJn5a00/aOYtk9ku6T9F3bd0jaJ2ltVzoEUIu2YY+IZyS5RfmmetsB0C2c7ABJEHYgCcIOJEHYgSQIO5AEX3HFeeuNq99ouoXzCkd2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCcXb0rXY/JY1zw94EkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQYZ0djTjz5O6X1MyNne9RJDhzZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJR0T5E+yVkr4taVhSSBqPiK/bvlfSX0o6XDz1noh4vOy1LvRQXGMmfgW6ZVts1dE4MuOsy7P5UM1pSV+IiOdsv0/Ss7a3FLX7I+If6moUQPfMZn72g5IOFveP2d4jaUW3GwNQr3N6z277UklXSdpWLNpg+3nbG20vabHOmO0J2xOndKJatwA6Nuuw236vpO9LujMijkp6QNLlkkY0deT/6kzrRcR4RIxGxOigFlTvGEBHZhV224OaCvp3IuIHkhQRhyLiTESclfRNSau71yaAqtqG3bYlPSRpT0R8bdry5dOedrukXfW3B6Aus7kaf62kT0vaaXtHseweSetsj2hqOG6vpM92oT8ANZnN1fhnJM00blc6pg6gv/AJOiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBJtf0q61o3ZhyXtm7boIkm/7FkD56Zfe+vXviR661SdvV0SETPOhd3TsL9r4/ZERIw21kCJfu2tX/uS6K1TveqN03ggCcIOJNF02Mcb3n6Zfu2tX/uS6K1TPemt0ffsAHqn6SM7gB4h7EASjYTd9i22/8v2y7bvbqKHVmzvtb3T9g7bEw33stH2pO1d05YN2d5i+6Xi74xz7DXU2722DxT7boftWxvqbaXtp2y/YHu37c8XyxvddyV99WS/9fw9u+0BSf8t6c8k7Ze0XdK6iHihp420YHuvpNGIaPwDGLZvkPS6pG9HxB8Uy74i6UhE3Ff8R7kkIu7qk97ulfR609N4F7MVLZ8+zbik2yT9hRrcdyV9rVUP9lsTR/bVkl6OiFci4qSkRyStaaCPvhcRT0s68o7FayRtKu5v0tQ/lp5r0VtfiIiDEfFccf+YpLemGW9035X01RNNhH2FpFenPd6v/prvPSQ9YftZ22NNNzOD4Yg4WNx/TdJwk83MoO003r30jmnG+2bfdTL9eVVcoHu36yLijyR9VNLnitPVvhRT78H6aex0VtN498oM04z/VpP7rtPpz6tqIuwHJK2c9vjiYllfiIgDxd9JSY+q/6aiPvTWDLrF38mG+/mtfprGe6ZpxtUH+67J6c+bCPt2SVfYvsz2fEmflLS5gT7exfbi4sKJbC+WdLP6byrqzZLWF/fXS3qswV7epl+m8W41zbga3neNT38eET2/SbpVU1fkfy7pr5vooUVfvyfpP4vb7qZ7k/Swpk7rTmnq2sYdkpZK2irpJUlPShrqo97+VdJOSc9rKljLG+rtOk2doj8vaUdxu7XpfVfSV0/2Gx+XBZLgAh2QBGEHkiDsQBKEHUiCsANJEHYgCcIOJPH/OLDzSn+ERVIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thrown-passage",
   "metadata": {},
   "source": [
    "### Cool, so our images are 28x28x1 arrays. This should be a little easier than RGB.\n",
    "\n",
    "Let's just rebuild our CNN from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "advance-plaintiff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLayer:\n",
    "    def __init__(self, num_filters, filter_size, strides=1):\n",
    "        self.num_filters = num_filters\n",
    "        self.strides = strides\n",
    "        self.filter_size = filter_size\n",
    "        self.filters = np.random.randn(num_filters, filter_size, filter_size) / (filter_size*filter_size)\n",
    "        \n",
    "    def patch_generator(self, image):\n",
    "        height, width = image.shape\n",
    "        self.image = image\n",
    "        \n",
    "        out_height, out_width, num_filters = self.out_size\n",
    "        \n",
    "        # iterate over image, yielding patches as we go\n",
    "        for i in range(out_height):\n",
    "            for j in range(out_width):\n",
    "                image_patch = image[i:i+self.filter_size, j:j+self.filter_size]\n",
    "                yield image_patch, i, j\n",
    "                \n",
    "    \n",
    "    def forward_prop(self, image):\n",
    "        height, width = image.shape\n",
    "        self.out_size = (int((height - self.filter_size) / self.strides + 1), int((width - self.filter_size) / self.strides + 1), self.num_filters)\n",
    "        conv_out = np.zeros(self.out_size)\n",
    "        \n",
    "        for image_patch, i, j in self.patch_generator(image):\n",
    "            conv_out[i, j] = np.sum(image_patch * self.filters, axis=(1,2))\n",
    "        \n",
    "        return conv_out\n",
    "    \n",
    "    \n",
    "    def backward_prop(self, dL_dout, learning_rate):\n",
    "        dL_dW_params = np.zeros(self.filters.shape)\n",
    "        \n",
    "        for image_patch, i, j in self.patch_generator(self.image):\n",
    "            for f in range(self.num_filters):\n",
    "                dL_dW_params[f] += image_patch * dL_dout[i,j,f]\n",
    "            \n",
    "        self.filters -= learning_rate*dL_dW_params\n",
    "        \n",
    "        return dL_dW_params\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "soviet-migration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27, 27, 4)\n"
     ]
    }
   ],
   "source": [
    "# Quick forward propagation test\n",
    "\n",
    "D = ConvLayer(num_filters=4, filter_size=2)\n",
    "out = D.forward_prop(images[0])\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "compressed-research",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPoolLayer:\n",
    "    def __init__(self, filter_size):\n",
    "        self.filter_size = filter_size\n",
    "        \n",
    "    def patch_generator(self, image):\n",
    "        self.image = image\n",
    "        out_height, out_width, out_depth = self.out_size\n",
    "        \n",
    "        for i in range(out_height):\n",
    "            for j in range(out_width):\n",
    "                image_patch = image[(i*self.filter_size):(self.filter_size*(i+1)), (j*self.filter_size):(self.filter_size*(j+1))]\n",
    "                yield image_patch, i, j\n",
    "        \n",
    "    def forward_prop(self, image):\n",
    "        inp_height, inp_width, inp_num_filters = image.shape\n",
    "        self.out_size = ((inp_height // self.filter_size), (inp_width // self.filter_size), inp_num_filters)\n",
    "        out = np.zeros(self.out_size)\n",
    "        \n",
    "        for patch, i, j in self.patch_generator(image):\n",
    "            out[i, j] = np.amax(patch, axis=(0,1))\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward_prop(self, dL_dout):\n",
    "        dL_dMP = np.zeros(self.image.shape)\n",
    "        \n",
    "        for patch, i, j in self.patch_generator(self.image):\n",
    "            ph, pw, pf = patch.shape\n",
    "            max_val = np.amax(patch, axis=(0,1))\n",
    "            \n",
    "            # Here we only want the gradient that corresponds to the\n",
    "            # maximum value from the input image to be updated\n",
    "        \n",
    "            for h in range(ph):\n",
    "                for w in range(pw):\n",
    "                    for f in range(pf):\n",
    "                        if patch[h,w,f] == max_val[f]:\n",
    "                            dL_dMP[i*self.filter_size + h, j*self.filter_size + w, f] = dL_dout[i,j,f]\n",
    "            \n",
    "            return dL_dMP\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "attended-baseline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 13, 4)\n"
     ]
    }
   ],
   "source": [
    "# Test out forward prop thru maxpool\n",
    "MP = MaxPoolLayer(2)\n",
    "mp_out = MP.forward_prop(out)\n",
    "print(mp_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "advisory-recovery",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxLayer:\n",
    "    def __init__(self, num_inputs, num_classes):\n",
    "        self.weights = np.random.randn(num_inputs, num_classes) / num_inputs\n",
    "        self.biases = np.zeros(num_classes)\n",
    "        \n",
    "        \n",
    "    def forward_prop(self, image):\n",
    "        self.orig_img_shape = image.shape\n",
    "        flattened = image.flatten()\n",
    "        self.flattened = flattened\n",
    "        out = np.dot(flattened, self.weights) + self.biases\n",
    "        print('weights: ', self.weights)\n",
    "        print('flattened: ', max(self.flattened))\n",
    "        self.out = out\n",
    "        exp_out = np.exp(out)\n",
    "        \n",
    "        return exp_out / np.sum(exp_out, axis=0)\n",
    "    \n",
    "    def backward_prop(self, dL_dout, learning_rate):\n",
    "        \n",
    "        # The gradient here will be the -log of our predicted y\n",
    "        # The rest of the values will be 0\n",
    "        for i, gradient in enumerate(dL_dout):\n",
    "            if gradient == 0:\n",
    "                continue\n",
    "                \n",
    "            exp = np.exp(self.out)\n",
    "            S_total = np.sum(exp)\n",
    "            \n",
    "            # case 2: i != l\n",
    "            dy_dz = -exp[i] * exp / (S_total**2)\n",
    "            \n",
    "            # case 1: i == l (this is equiv. to y*(1-y))\n",
    "            dy_dz[i] = exp[i]*(S_total - exp[i]) / (S_total**2)\n",
    "            \n",
    "            # dz_dw, dz_db, dz_dinput\n",
    "            dz_dw = self.flattened\n",
    "            dz_db = 1\n",
    "            dz_dinput = self.weights\n",
    "            \n",
    "            # grad is dL_dy\n",
    "            # dL/dz = dL/dy * dy/dz\n",
    "            dL_dz = gradient * dy_dz\n",
    "            \n",
    "            # loss wrt. weights, biases, input\n",
    "            dL_dW = dz_dw[np.newaxis].T @ dL_dz[np.newaxis]\n",
    "            dL_db = dL_dz * dz_db\n",
    "            dL_dinput = dz_dinput @ dL_dz\n",
    "            \n",
    "            # update weights and biases\n",
    "            self.weights = self.weights - (learning_rate * dL_dW)\n",
    "            self.biases = self.biases - (learning_rate * dL_db)\n",
    "            \n",
    "            return dL_dinput.reshape(self.orig_img_shape)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "billion-student",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights:  [[ 6.84303229e-04  1.44703948e-03 -1.16748854e-03 ... -1.23821602e-04\n",
      "  -1.64395162e-03 -3.19932154e-04]\n",
      " [-1.79169757e-04 -1.65434911e-03  5.48089663e-04 ...  2.44365151e-03\n",
      "  -2.47236430e-03 -4.30287478e-04]\n",
      " [-8.72104268e-04  7.90317671e-04 -1.55832210e-03 ...  3.30992212e-03\n",
      "  -8.16545437e-04 -2.62090024e-03]\n",
      " ...\n",
      " [-6.41925388e-05  1.60459125e-03 -9.36936180e-04 ...  1.15351315e-04\n",
      "  -2.64329546e-03 -2.95264567e-04]\n",
      " [ 3.14744620e-03  3.05515387e-03  9.07607368e-04 ... -2.52507586e-04\n",
      "  -6.88837519e-04  2.53991509e-04]\n",
      " [-1.25431818e-03 -1.61185409e-03  4.65730916e-05 ... -5.44517571e-04\n",
      "  -1.23283158e-03  4.59909462e-04]]\n",
      "flattened:  0.7126646951180666\n",
      "[0.09968671 0.09895606 0.09914998 0.10012274 0.09967732 0.09996651\n",
      " 0.10063664 0.10087747 0.10109838 0.09982817]\n"
     ]
    }
   ],
   "source": [
    "from math import prod\n",
    "\n",
    "SM = SoftmaxLayer(num_inputs=prod(mp_out.shape), num_classes=10)\n",
    "sm_out = SM.forward_prop(mp_out)\n",
    "print(sm_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worse-judgment",
   "metadata": {},
   "source": [
    "## This softmax output is promising\n",
    "This is actually way more promising than the CIFAR CNN at this stage\n",
    "\n",
    "The output of the softmax *should* look like this (approx. equal probabilities because we have done zero training), and on the CIFAR it looked far more random than this.\n",
    "\n",
    "So maybe I have something wrong with my forward propagation on the other attempt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "stock-trick",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 13, 4)\n",
      "(27, 27, 4)\n",
      "(4, 2, 2)\n"
     ]
    }
   ],
   "source": [
    "# Moment of truth: backpropagation\n",
    "\n",
    "image_label = labels[0]\n",
    "num_classes = 10\n",
    "learning_rate = 0.005\n",
    "\n",
    "# Cross-entropy-loss\n",
    "def initial_gradient (sm_out, image_label):\n",
    "    cross_entropy_loss = -np.log(sm_out[image_label])\n",
    "    acc = 1 if np.argmax(sm_out) == image_label else 0\n",
    "\n",
    "    gradient = np.zeros(num_classes)\n",
    "    gradient[image_label] = -1 / sm_out[image_label]\n",
    "    \n",
    "    return gradient\n",
    "\n",
    "gradient = initial_gradient(sm_out, image_label)\n",
    "\n",
    "gradient = SM.backward_prop(gradient, learning_rate)\n",
    "print(gradient.shape)\n",
    "gradient = MP.backward_prop(gradient)\n",
    "print(gradient.shape)\n",
    "gradient = D.backward_prop(gradient, learning_rate)\n",
    "print(gradient.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "meaning-sapphire",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10845248 0.09911881 0.09891256 0.09832081 0.09943338 0.09930509\n",
      " 0.09901739 0.09955113 0.09907859 0.09880976]\n",
      "(4, 2, 2)\n"
     ]
    }
   ],
   "source": [
    "# Second moment of truth: feeding in a 2nd image\n",
    "\n",
    "img2 = images[2]\n",
    "label = labels[2]\n",
    "\n",
    "fwd = D.forward_prop(img2)\n",
    "fwd = MP.forward_prop(fwd)\n",
    "fwd = SM.forward_prop(fwd)\n",
    "print(fwd)\n",
    "\n",
    "gradient = initial_gradient(fwd, label)\n",
    "\n",
    "back = SM.backward_prop(gradient, learning_rate)\n",
    "back = MP.backward_prop(back)\n",
    "back = D.backward_prop(back, learning_rate)\n",
    "print(back.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "activated-strike",
   "metadata": {},
   "source": [
    "### Alright! No real change but no exploding/vanishing gradient immediately, so we'll train on many images and see what happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "minor-parker",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is partly reused code from cnn_cifar.ipynb\n",
    "\n",
    "class CNNModel:\n",
    "    def __init__(self, layers, num_classes, learning_rate=0.005):\n",
    "        assert len(layers) >= 1\n",
    "        self.layers = layers\n",
    "        self.num_classes = num_classes\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "    def forward_prop(self, image, label):\n",
    "        out_forward = self.layers[0].forward_prop(image)\n",
    "        for layer in self.layers[1:]:\n",
    "            out_forward = layer.forward_prop(out_forward)\n",
    "        \n",
    "        cross_entropy_loss = -np.log(out_forward[label])\n",
    "        accuracy = 0\n",
    "        if np.argmax(out_forward) == label:\n",
    "            accuracy = 1\n",
    "        \n",
    "        return out_forward, cross_entropy_loss, accuracy\n",
    "    \n",
    "    def backward_prop(self, initial_gradient):\n",
    "        back_gradient = self.layers[-1].backward_prop(initial_gradient, self.learning_rate)\n",
    "        for layer in reversed(self.layers[:-1]):\n",
    "            if isinstance(layer, MaxPoolLayer):\n",
    "                back_gradient = layer.backward_prop(back_gradient)\n",
    "            else:\n",
    "                back_gradient = layer.backward_prop(back_gradient, self.learning_rate)\n",
    "    \n",
    "    def train_image(self, image, label):\n",
    "        \n",
    "        # Forward propagation\n",
    "        out_fw, loss, acc = self.forward_prop(image, label)\n",
    "        # calc initial gradient\n",
    "        gradient = np.zeros(self.num_classes)\n",
    "        gradient[label] = -1 / out_fw[label]\n",
    "        \n",
    "        # Backward propagation\n",
    "        self.backward_prop(gradient)\n",
    "        \n",
    "        return loss, acc\n",
    "    \n",
    "    def train(self, images, labels):\n",
    "        loss = 0\n",
    "        num_correct = 0\n",
    "        for i, (img, label) in enumerate(zip(images, labels)):\n",
    "            if i % 100 == 0:\n",
    "                print('after {num} images, loss={loss} and correct%={correct}'.format(num=i, loss=loss, correct=(num_correct/100)))\n",
    "                loss = 0\n",
    "                num_correct = 0\n",
    "            \n",
    "            l, a = self.train_image(img, label)\n",
    "            loss += l\n",
    "            num_correct += a\n",
    "\n",
    "model_test = CNNModel(\n",
    "    layers=[\n",
    "        ConvLayer(num_filters=4, filter_size=4),\n",
    "        MaxPoolLayer(2),\n",
    "        SoftmaxLayer(num_inputs=12*12*4, num_classes=10)\n",
    "    ],\n",
    "    num_classes=10,\n",
    "    learning_rate=0.005\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "comic-michael",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2977086246321594 0\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model_test.train_image(images[0], labels[0])\n",
    "print(loss, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "gothic-namibia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's set up some training and testing data\n",
    "# images contains 59999 images\n",
    "\n",
    "train_set = images[:50000]\n",
    "train_labels = labels[:50000]\n",
    "\n",
    "test_set = images[50000:]\n",
    "test_labels = labels[50000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "educational-genius",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 0 images, loss=0 and correct%=0.0\n",
      "after 100 images, loss=228.3322244196201 and correct%=0.24\n",
      "after 200 images, loss=225.04558837957137 and correct%=0.39\n",
      "after 300 images, loss=221.38681538148006 and correct%=0.61\n",
      "after 400 images, loss=217.95629460391243 and correct%=0.7\n",
      "after 500 images, loss=215.53734498392126 and correct%=0.66\n",
      "after 600 images, loss=215.22334798557947 and correct%=0.62\n",
      "after 700 images, loss=212.89179814884645 and correct%=0.57\n",
      "after 800 images, loss=208.11056613934628 and correct%=0.68\n",
      "after 900 images, loss=204.4946800137935 and correct%=0.74\n",
      "after 1000 images, loss=202.4850617697718 and correct%=0.72\n",
      "after 1100 images, loss=202.459564266516 and correct%=0.64\n",
      "after 1200 images, loss=199.02742862307858 and correct%=0.69\n",
      "after 1300 images, loss=200.73122771723723 and correct%=0.6\n",
      "after 1400 images, loss=192.1860624180741 and correct%=0.76\n",
      "after 1500 images, loss=191.63238915680824 and correct%=0.74\n",
      "after 1600 images, loss=190.35865869084572 and correct%=0.74\n",
      "after 1700 images, loss=181.92263898809458 and correct%=0.75\n",
      "after 1800 images, loss=177.10812418295018 and correct%=0.77\n",
      "after 1900 images, loss=178.06272533842775 and correct%=0.77\n",
      "after 2000 images, loss=178.70618009810127 and correct%=0.72\n",
      "after 2100 images, loss=175.92685660360542 and correct%=0.79\n",
      "after 2200 images, loss=167.93116265858026 and correct%=0.8\n",
      "after 2300 images, loss=167.9000143940311 and correct%=0.81\n",
      "after 2400 images, loss=170.43094144823735 and correct%=0.79\n",
      "after 2500 images, loss=168.1847968166705 and correct%=0.79\n",
      "after 2600 images, loss=160.77313328555198 and correct%=0.83\n",
      "after 2700 images, loss=160.3168649146353 and correct%=0.78\n",
      "after 2800 images, loss=161.9815480972635 and correct%=0.75\n",
      "after 2900 images, loss=150.70579370309994 and correct%=0.81\n",
      "after 3000 images, loss=157.47431107603498 and correct%=0.76\n",
      "after 3100 images, loss=161.59502549638285 and correct%=0.79\n",
      "after 3200 images, loss=154.37676419103988 and correct%=0.8\n",
      "after 3300 images, loss=153.5793265116102 and correct%=0.78\n",
      "after 3400 images, loss=149.80881769894984 and correct%=0.83\n",
      "after 3500 images, loss=152.85171316767747 and correct%=0.81\n",
      "after 3600 images, loss=147.8158390032267 and correct%=0.74\n",
      "after 3700 images, loss=140.36803100363332 and correct%=0.81\n",
      "after 3800 images, loss=140.37809978274257 and correct%=0.84\n",
      "after 3900 images, loss=140.04832394605086 and correct%=0.79\n",
      "after 4000 images, loss=145.011177940718 and correct%=0.79\n",
      "after 4100 images, loss=140.08479346711496 and correct%=0.84\n",
      "after 4200 images, loss=141.8293274184147 and correct%=0.81\n",
      "after 4300 images, loss=131.1947706836533 and correct%=0.88\n",
      "after 4400 images, loss=139.21483362475513 and correct%=0.83\n",
      "after 4500 images, loss=138.93270481529888 and correct%=0.82\n",
      "after 4600 images, loss=121.76785994785835 and correct%=0.84\n",
      "after 4700 images, loss=133.61582628838846 and correct%=0.72\n",
      "after 4800 images, loss=137.48320820049022 and correct%=0.85\n",
      "after 4900 images, loss=135.17224400449848 and correct%=0.8\n",
      "after 5000 images, loss=130.03861980728212 and correct%=0.83\n",
      "after 5100 images, loss=127.12186395988203 and correct%=0.81\n",
      "after 5200 images, loss=129.8162153561349 and correct%=0.77\n",
      "after 5300 images, loss=119.80743750016725 and correct%=0.89\n",
      "after 5400 images, loss=121.64853656135521 and correct%=0.77\n",
      "after 5500 images, loss=113.38291624078445 and correct%=0.86\n",
      "after 5600 images, loss=119.06441671919212 and correct%=0.83\n",
      "after 5700 images, loss=123.41699222766867 and correct%=0.82\n",
      "after 5800 images, loss=126.58159607433312 and correct%=0.82\n",
      "after 5900 images, loss=122.98363660672514 and correct%=0.85\n",
      "after 6000 images, loss=116.62771407036035 and correct%=0.86\n",
      "after 6100 images, loss=106.97659048087685 and correct%=0.87\n",
      "after 6200 images, loss=110.72607021028904 and correct%=0.83\n",
      "after 6300 images, loss=116.46368704120111 and correct%=0.83\n",
      "after 6400 images, loss=113.63595501600685 and correct%=0.86\n",
      "after 6500 images, loss=120.4678706918403 and correct%=0.8\n",
      "after 6600 images, loss=96.6836230594263 and correct%=0.88\n",
      "after 6700 images, loss=109.67323618136952 and correct%=0.87\n",
      "after 6800 images, loss=114.84479333243554 and correct%=0.84\n",
      "after 6900 images, loss=128.63489128274523 and correct%=0.76\n",
      "after 7000 images, loss=114.5513872494286 and correct%=0.75\n",
      "after 7100 images, loss=114.27815324311278 and correct%=0.81\n",
      "after 7200 images, loss=115.28719600701702 and correct%=0.88\n",
      "after 7300 images, loss=135.340196903967 and correct%=0.74\n",
      "after 7400 images, loss=123.22527805957188 and correct%=0.82\n",
      "after 7500 images, loss=114.8291013050877 and correct%=0.73\n",
      "after 7600 images, loss=111.77159110493477 and correct%=0.84\n",
      "after 7700 images, loss=113.78960209797023 and correct%=0.81\n",
      "after 7800 images, loss=115.61562898919567 and correct%=0.8\n",
      "after 7900 images, loss=110.22274572606953 and correct%=0.81\n",
      "after 8000 images, loss=105.81254048012283 and correct%=0.8\n",
      "after 8100 images, loss=100.1923998146564 and correct%=0.83\n",
      "after 8200 images, loss=111.87634896193295 and correct%=0.78\n",
      "after 8300 images, loss=115.59098362650872 and correct%=0.8\n",
      "after 8400 images, loss=101.18071262603904 and correct%=0.9\n",
      "after 8500 images, loss=111.33395903301314 and correct%=0.85\n",
      "after 8600 images, loss=89.37814462139734 and correct%=0.9\n",
      "after 8700 images, loss=111.51896845836285 and correct%=0.77\n",
      "after 8800 images, loss=124.47867362687481 and correct%=0.74\n",
      "after 8900 images, loss=122.28737069687578 and correct%=0.68\n",
      "after 9000 images, loss=91.36433932962976 and correct%=0.79\n",
      "after 9100 images, loss=95.26259953485184 and correct%=0.87\n",
      "after 9200 images, loss=100.19178845400025 and correct%=0.86\n",
      "after 9300 images, loss=103.23626479815339 and correct%=0.8\n",
      "after 9400 images, loss=98.99085452487708 and correct%=0.81\n",
      "after 9500 images, loss=89.05883904320052 and correct%=0.87\n",
      "after 9600 images, loss=105.25040382365367 and correct%=0.82\n",
      "after 9700 images, loss=92.08087658420531 and correct%=0.87\n",
      "after 9800 images, loss=90.8597227369749 and correct%=0.82\n",
      "after 9900 images, loss=80.9063993205923 and correct%=0.9\n",
      "after 10000 images, loss=82.65016999917148 and correct%=0.88\n",
      "after 10100 images, loss=93.44688466335037 and correct%=0.85\n",
      "after 10200 images, loss=94.32938149815335 and correct%=0.86\n",
      "after 10300 images, loss=104.76578951231937 and correct%=0.77\n",
      "after 10400 images, loss=77.14186553432329 and correct%=0.88\n",
      "after 10500 images, loss=82.12732466077915 and correct%=0.86\n",
      "after 10600 images, loss=82.28581598578286 and correct%=0.9\n",
      "after 10700 images, loss=85.84809103903109 and correct%=0.91\n",
      "after 10800 images, loss=99.28774215250134 and correct%=0.8\n",
      "after 10900 images, loss=80.29967815241639 and correct%=0.87\n",
      "after 11000 images, loss=84.23099144267424 and correct%=0.9\n",
      "after 11100 images, loss=75.19526386336132 and correct%=0.9\n",
      "after 11200 images, loss=86.16454256489745 and correct%=0.86\n",
      "after 11300 images, loss=90.3369111990986 and correct%=0.84\n",
      "after 11400 images, loss=87.43049288994854 and correct%=0.83\n",
      "after 11500 images, loss=81.00842720301272 and correct%=0.87\n",
      "after 11600 images, loss=100.63592936856068 and correct%=0.76\n",
      "after 11700 images, loss=99.43687278366463 and correct%=0.79\n",
      "after 11800 images, loss=104.95367233137961 and correct%=0.73\n",
      "after 11900 images, loss=91.86241510865045 and correct%=0.82\n",
      "after 12000 images, loss=90.11810433534411 and correct%=0.85\n",
      "after 12100 images, loss=83.03457472704503 and correct%=0.86\n",
      "after 12200 images, loss=81.22818985315399 and correct%=0.9\n",
      "after 12300 images, loss=85.18012798128873 and correct%=0.82\n",
      "after 12400 images, loss=96.88999756510724 and correct%=0.84\n",
      "after 12500 images, loss=91.0521326069239 and correct%=0.79\n",
      "after 12600 images, loss=93.02003920475501 and correct%=0.82\n",
      "after 12700 images, loss=100.45768617410263 and correct%=0.79\n",
      "after 12800 images, loss=86.1657500210126 and correct%=0.83\n",
      "after 12900 images, loss=82.1142298833808 and correct%=0.86\n",
      "after 13000 images, loss=98.74809206620378 and correct%=0.8\n",
      "after 13100 images, loss=111.37082568167983 and correct%=0.73\n",
      "after 13200 images, loss=94.34672637237331 and correct%=0.8\n",
      "after 13300 images, loss=79.12922944258928 and correct%=0.85\n",
      "after 13400 images, loss=94.58029141655913 and correct%=0.76\n",
      "after 13500 images, loss=68.11783150332901 and correct%=0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 13600 images, loss=64.52985843619761 and correct%=0.87\n",
      "after 13700 images, loss=89.36801656512986 and correct%=0.79\n",
      "after 13800 images, loss=89.48932547716748 and correct%=0.81\n",
      "after 13900 images, loss=82.91909002006008 and correct%=0.85\n",
      "after 14000 images, loss=98.75874745639555 and correct%=0.71\n",
      "after 14100 images, loss=87.0757994410113 and correct%=0.82\n",
      "after 14200 images, loss=88.82819481238245 and correct%=0.79\n",
      "after 14300 images, loss=97.05676843600148 and correct%=0.79\n",
      "after 14400 images, loss=102.37598907585084 and correct%=0.73\n",
      "after 14500 images, loss=83.96984252364865 and correct%=0.82\n",
      "after 14600 images, loss=91.41000566819946 and correct%=0.8\n",
      "after 14700 images, loss=116.20923004833521 and correct%=0.68\n",
      "after 14800 images, loss=110.29323085906505 and correct%=0.69\n",
      "after 14900 images, loss=84.8548391881998 and correct%=0.82\n",
      "after 15000 images, loss=80.67792954074325 and correct%=0.85\n",
      "after 15100 images, loss=69.13578689318726 and correct%=0.9\n",
      "after 15200 images, loss=89.44304118370663 and correct%=0.81\n",
      "after 15300 images, loss=76.87052589602243 and correct%=0.82\n",
      "after 15400 images, loss=75.34675262234784 and correct%=0.89\n",
      "after 15500 images, loss=75.86738942073598 and correct%=0.85\n",
      "after 15600 images, loss=76.02260552298425 and correct%=0.86\n",
      "after 15700 images, loss=72.2109309139813 and correct%=0.88\n",
      "after 15800 images, loss=104.44555174450952 and correct%=0.72\n",
      "after 15900 images, loss=96.44746541363088 and correct%=0.74\n",
      "after 16000 images, loss=82.35622627209148 and correct%=0.84\n",
      "after 16100 images, loss=95.0270656968926 and correct%=0.75\n",
      "after 16200 images, loss=79.7792967118499 and correct%=0.81\n",
      "after 16300 images, loss=74.55996954312948 and correct%=0.87\n",
      "after 16400 images, loss=77.79239118571218 and correct%=0.83\n",
      "after 16500 images, loss=69.32197877067057 and correct%=0.92\n",
      "after 16600 images, loss=70.7031843720704 and correct%=0.86\n",
      "after 16700 images, loss=79.5461922093819 and correct%=0.84\n",
      "after 16800 images, loss=84.293269851893 and correct%=0.8\n",
      "after 16900 images, loss=83.28305898433341 and correct%=0.83\n",
      "after 17000 images, loss=87.63843491784941 and correct%=0.77\n",
      "after 17100 images, loss=88.4146388262686 and correct%=0.8\n",
      "after 17200 images, loss=74.49929215038775 and correct%=0.82\n",
      "after 17300 images, loss=86.42761778950504 and correct%=0.82\n",
      "after 17400 images, loss=66.4311266955856 and correct%=0.91\n",
      "after 17500 images, loss=79.31011050997672 and correct%=0.84\n",
      "after 17600 images, loss=95.76669317873876 and correct%=0.74\n",
      "after 17700 images, loss=86.16385187637502 and correct%=0.81\n",
      "after 17800 images, loss=90.73771507451075 and correct%=0.82\n",
      "after 17900 images, loss=87.48304520654368 and correct%=0.85\n",
      "after 18000 images, loss=64.19227258831279 and correct%=0.9\n",
      "after 18100 images, loss=76.21278394742419 and correct%=0.87\n",
      "after 18200 images, loss=60.45846219654843 and correct%=0.9\n",
      "after 18300 images, loss=68.40655357890283 and correct%=0.89\n",
      "after 18400 images, loss=74.19074980233972 and correct%=0.87\n",
      "after 18500 images, loss=86.7124261768404 and correct%=0.8\n",
      "after 18600 images, loss=66.70600901454854 and correct%=0.93\n",
      "after 18700 images, loss=69.48235741339172 and correct%=0.89\n",
      "after 18800 images, loss=61.9225472580597 and correct%=0.92\n",
      "after 18900 images, loss=65.75987380478387 and correct%=0.91\n",
      "after 19000 images, loss=62.738827554612016 and correct%=0.93\n",
      "after 19100 images, loss=80.25254445357635 and correct%=0.82\n",
      "after 19200 images, loss=76.70350011005942 and correct%=0.85\n",
      "after 19300 images, loss=68.38099284063172 and correct%=0.87\n",
      "after 19400 images, loss=72.51013210437861 and correct%=0.84\n",
      "after 19500 images, loss=62.99269493717459 and correct%=0.87\n",
      "after 19600 images, loss=76.78070230883404 and correct%=0.83\n",
      "after 19700 images, loss=57.218326837434155 and correct%=0.9\n",
      "after 19800 images, loss=48.93746459629957 and correct%=0.94\n",
      "after 19900 images, loss=70.3873793676063 and correct%=0.8\n",
      "after 20000 images, loss=77.76414650028944 and correct%=0.84\n",
      "after 20100 images, loss=87.59368327851024 and correct%=0.78\n",
      "after 20200 images, loss=71.78141329356238 and correct%=0.86\n",
      "after 20300 images, loss=73.01916419618665 and correct%=0.88\n",
      "after 20400 images, loss=62.51735359280037 and correct%=0.89\n",
      "after 20500 images, loss=55.81212761485396 and correct%=0.9\n",
      "after 20600 images, loss=68.48016952747872 and correct%=0.84\n",
      "after 20700 images, loss=62.3720493391814 and correct%=0.86\n",
      "after 20800 images, loss=73.77732469993423 and correct%=0.84\n",
      "after 20900 images, loss=77.23004576685615 and correct%=0.84\n",
      "after 21000 images, loss=85.53581920908462 and correct%=0.81\n",
      "after 21100 images, loss=61.736391732567114 and correct%=0.91\n",
      "after 21200 images, loss=60.224879667986876 and correct%=0.87\n",
      "after 21300 images, loss=51.558887081671465 and correct%=0.92\n",
      "after 21400 images, loss=74.44628964528034 and correct%=0.82\n",
      "after 21500 images, loss=66.45712458059793 and correct%=0.87\n",
      "after 21600 images, loss=67.48883931248888 and correct%=0.86\n",
      "after 21700 images, loss=65.06844475700758 and correct%=0.88\n",
      "after 21800 images, loss=56.108185929918264 and correct%=0.92\n",
      "after 21900 images, loss=53.364840170427456 and correct%=0.92\n",
      "after 22000 images, loss=55.8291202816108 and correct%=0.9\n",
      "after 22100 images, loss=62.97876939507824 and correct%=0.9\n",
      "after 22200 images, loss=89.16884673687336 and correct%=0.74\n",
      "after 22300 images, loss=73.25021907911118 and correct%=0.87\n",
      "after 22400 images, loss=57.82817398320958 and correct%=0.87\n",
      "after 22500 images, loss=80.05612276263186 and correct%=0.8\n",
      "after 22600 images, loss=104.17242255603855 and correct%=0.71\n",
      "after 22700 images, loss=79.87548741157129 and correct%=0.82\n",
      "after 22800 images, loss=68.57913070055946 and correct%=0.81\n",
      "after 22900 images, loss=61.74939698186068 and correct%=0.88\n",
      "after 23000 images, loss=52.702315487176975 and correct%=0.92\n",
      "after 23100 images, loss=65.34326613133375 and correct%=0.87\n",
      "after 23200 images, loss=66.9315315281555 and correct%=0.85\n",
      "after 23300 images, loss=59.529571121033115 and correct%=0.86\n",
      "after 23400 images, loss=63.2478130153458 and correct%=0.88\n",
      "after 23500 images, loss=64.63244226264092 and correct%=0.86\n",
      "after 23600 images, loss=61.68747313131587 and correct%=0.89\n",
      "after 23700 images, loss=68.01908814025191 and correct%=0.88\n",
      "after 23800 images, loss=68.13114072888303 and correct%=0.86\n",
      "after 23900 images, loss=71.1393344142786 and correct%=0.81\n",
      "after 24000 images, loss=65.06225556825373 and correct%=0.9\n",
      "after 24100 images, loss=64.95418330908514 and correct%=0.88\n",
      "after 24200 images, loss=59.34945898379958 and correct%=0.88\n",
      "after 24300 images, loss=78.03155811170768 and correct%=0.81\n",
      "after 24400 images, loss=63.11794644330258 and correct%=0.87\n",
      "after 24500 images, loss=67.292804890433 and correct%=0.82\n",
      "after 24600 images, loss=72.23196766069827 and correct%=0.85\n",
      "after 24700 images, loss=71.08975127178867 and correct%=0.82\n",
      "after 24800 images, loss=86.12278228282133 and correct%=0.78\n",
      "after 24900 images, loss=66.81552251825791 and correct%=0.87\n",
      "after 25000 images, loss=77.16523504385707 and correct%=0.81\n",
      "after 25100 images, loss=55.44596205528223 and correct%=0.84\n",
      "after 25200 images, loss=59.978121514932994 and correct%=0.83\n",
      "after 25300 images, loss=59.58839370757882 and correct%=0.85\n",
      "after 25400 images, loss=63.62180763042967 and correct%=0.87\n",
      "after 25500 images, loss=59.192088310599885 and correct%=0.85\n",
      "after 25600 images, loss=54.64656319252035 and correct%=0.9\n",
      "after 25700 images, loss=55.266556764933206 and correct%=0.91\n",
      "after 25800 images, loss=60.37335185996503 and correct%=0.87\n",
      "after 25900 images, loss=64.93774713124469 and correct%=0.87\n",
      "after 26000 images, loss=68.30813595241143 and correct%=0.83\n",
      "after 26100 images, loss=54.73039074036491 and correct%=0.88\n",
      "after 26200 images, loss=53.7547264307693 and correct%=0.92\n",
      "after 26300 images, loss=65.13265074235808 and correct%=0.88\n",
      "after 26400 images, loss=71.94896174928299 and correct%=0.86\n",
      "after 26500 images, loss=67.2105344713604 and correct%=0.84\n",
      "after 26600 images, loss=71.3283304344845 and correct%=0.83\n",
      "after 26700 images, loss=74.88130411565977 and correct%=0.83\n",
      "after 26800 images, loss=72.82240639876913 and correct%=0.82\n",
      "after 26900 images, loss=72.16028434378866 and correct%=0.84\n",
      "after 27000 images, loss=56.4876438662524 and correct%=0.88\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 27100 images, loss=57.09724421584202 and correct%=0.89\n",
      "after 27200 images, loss=75.47215708964211 and correct%=0.81\n",
      "after 27300 images, loss=63.00918387373591 and correct%=0.87\n",
      "after 27400 images, loss=60.44009598588798 and correct%=0.88\n",
      "after 27500 images, loss=64.37813284586906 and correct%=0.83\n",
      "after 27600 images, loss=54.8669945354856 and correct%=0.9\n",
      "after 27700 images, loss=66.87799634999176 and correct%=0.86\n",
      "after 27800 images, loss=64.01620647601224 and correct%=0.89\n",
      "after 27900 images, loss=59.00621856650822 and correct%=0.88\n",
      "after 28000 images, loss=51.9716618118747 and correct%=0.89\n",
      "after 28100 images, loss=42.167993476505515 and correct%=0.94\n",
      "after 28200 images, loss=66.91205090651825 and correct%=0.86\n",
      "after 28300 images, loss=53.266167240143616 and correct%=0.89\n",
      "after 28400 images, loss=70.8606789944171 and correct%=0.85\n",
      "after 28500 images, loss=49.99057119344097 and correct%=0.92\n",
      "after 28600 images, loss=58.53130351329503 and correct%=0.87\n",
      "after 28700 images, loss=81.01900455699158 and correct%=0.79\n",
      "after 28800 images, loss=60.914864615800894 and correct%=0.87\n",
      "after 28900 images, loss=51.90805448052649 and correct%=0.88\n",
      "after 29000 images, loss=57.35997209472348 and correct%=0.85\n",
      "after 29100 images, loss=67.03813513339983 and correct%=0.81\n",
      "after 29200 images, loss=79.74312441860322 and correct%=0.8\n",
      "after 29300 images, loss=57.697682830370276 and correct%=0.89\n",
      "after 29400 images, loss=65.68420189278407 and correct%=0.85\n",
      "after 29500 images, loss=49.77591844202199 and correct%=0.87\n",
      "after 29600 images, loss=59.32904357594111 and correct%=0.85\n",
      "after 29700 images, loss=54.74230155739525 and correct%=0.9\n",
      "after 29800 images, loss=80.79696477551022 and correct%=0.8\n",
      "after 29900 images, loss=77.93336186692594 and correct%=0.79\n",
      "after 30000 images, loss=78.00988627598008 and correct%=0.81\n",
      "after 30100 images, loss=68.6270533704765 and correct%=0.83\n",
      "after 30200 images, loss=86.01008006575256 and correct%=0.78\n",
      "after 30300 images, loss=54.82495873432085 and correct%=0.93\n",
      "after 30400 images, loss=62.00439309139879 and correct%=0.84\n",
      "after 30500 images, loss=67.41251809557203 and correct%=0.8\n",
      "after 30600 images, loss=73.80424206334676 and correct%=0.83\n",
      "after 30700 images, loss=76.96495462835688 and correct%=0.85\n",
      "after 30800 images, loss=63.54985095180542 and correct%=0.88\n",
      "after 30900 images, loss=77.26832114239843 and correct%=0.8\n",
      "after 31000 images, loss=58.7956485990082 and correct%=0.89\n",
      "after 31100 images, loss=64.31986219532591 and correct%=0.86\n",
      "after 31200 images, loss=65.51374887035291 and correct%=0.87\n",
      "after 31300 images, loss=64.74182731813886 and correct%=0.86\n",
      "after 31400 images, loss=86.73427896414148 and correct%=0.79\n",
      "after 31500 images, loss=65.072134537809 and correct%=0.86\n",
      "after 31600 images, loss=59.008800649126265 and correct%=0.86\n",
      "after 31700 images, loss=76.42506747251056 and correct%=0.79\n",
      "after 31800 images, loss=79.05213768880655 and correct%=0.78\n",
      "after 31900 images, loss=57.26891307439548 and correct%=0.88\n",
      "after 32000 images, loss=61.217894125418276 and correct%=0.87\n",
      "after 32100 images, loss=59.564861514935295 and correct%=0.83\n",
      "after 32200 images, loss=73.61776373852541 and correct%=0.82\n",
      "after 32300 images, loss=77.48923579797217 and correct%=0.82\n",
      "after 32400 images, loss=81.07037000176717 and correct%=0.76\n",
      "after 32500 images, loss=78.28289354848737 and correct%=0.79\n",
      "after 32600 images, loss=63.6348379030539 and correct%=0.84\n",
      "after 32700 images, loss=54.23532954456813 and correct%=0.89\n",
      "after 32800 images, loss=63.71195106768398 and correct%=0.86\n",
      "after 32900 images, loss=56.46040135879561 and correct%=0.9\n",
      "after 33000 images, loss=55.26213421230135 and correct%=0.92\n",
      "after 33100 images, loss=67.24805594846111 and correct%=0.84\n",
      "after 33200 images, loss=57.928827754713986 and correct%=0.9\n",
      "after 33300 images, loss=65.26040666808409 and correct%=0.88\n",
      "after 33400 images, loss=69.60690883286513 and correct%=0.8\n",
      "after 33500 images, loss=59.75027564757215 and correct%=0.85\n",
      "after 33600 images, loss=56.175635172084625 and correct%=0.89\n",
      "after 33700 images, loss=50.271846758529975 and correct%=0.88\n",
      "after 33800 images, loss=53.460126041075604 and correct%=0.89\n",
      "after 33900 images, loss=42.34113827008377 and correct%=0.93\n",
      "after 34000 images, loss=39.87354167252119 and correct%=0.93\n",
      "after 34100 images, loss=61.56158350834399 and correct%=0.88\n",
      "after 34200 images, loss=49.10795304900657 and correct%=0.91\n",
      "after 34300 images, loss=42.154085440813255 and correct%=0.94\n",
      "after 34400 images, loss=52.93432542009383 and correct%=0.88\n",
      "after 34500 images, loss=67.40994274990346 and correct%=0.87\n",
      "after 34600 images, loss=60.28643525637256 and correct%=0.82\n",
      "after 34700 images, loss=61.098997524570756 and correct%=0.85\n",
      "after 34800 images, loss=68.49921506916272 and correct%=0.8\n",
      "after 34900 images, loss=75.31727074089027 and correct%=0.82\n",
      "after 35000 images, loss=58.86272400303659 and correct%=0.84\n",
      "after 35100 images, loss=49.8855543653661 and correct%=0.92\n",
      "after 35200 images, loss=59.496532408876526 and correct%=0.86\n",
      "after 35300 images, loss=59.26759805981407 and correct%=0.89\n",
      "after 35400 images, loss=48.5728472874642 and correct%=0.91\n",
      "after 35500 images, loss=59.45363978576534 and correct%=0.85\n",
      "after 35600 images, loss=47.01743495800119 and correct%=0.92\n",
      "after 35700 images, loss=65.94877292959528 and correct%=0.83\n",
      "after 35800 images, loss=50.21883295954332 and correct%=0.87\n",
      "after 35900 images, loss=49.51049735710531 and correct%=0.9\n",
      "after 36000 images, loss=62.87533395453107 and correct%=0.8\n",
      "after 36100 images, loss=73.31380157211765 and correct%=0.8\n",
      "after 36200 images, loss=50.880857873806185 and correct%=0.9\n",
      "after 36300 images, loss=44.69732397170591 and correct%=0.9\n",
      "after 36400 images, loss=48.11501060014778 and correct%=0.86\n",
      "after 36500 images, loss=73.91064095444241 and correct%=0.85\n",
      "after 36600 images, loss=49.12096047096705 and correct%=0.88\n",
      "after 36700 images, loss=42.81953596190942 and correct%=0.93\n",
      "after 36800 images, loss=52.87435357636308 and correct%=0.86\n",
      "after 36900 images, loss=58.68177756435567 and correct%=0.85\n",
      "after 37000 images, loss=44.40017700713348 and correct%=0.92\n",
      "after 37100 images, loss=63.36381200114266 and correct%=0.83\n",
      "after 37200 images, loss=58.23318629016522 and correct%=0.89\n",
      "after 37300 images, loss=60.85841722473669 and correct%=0.85\n",
      "after 37400 images, loss=76.11382724048087 and correct%=0.81\n",
      "after 37500 images, loss=81.1293949684388 and correct%=0.8\n",
      "after 37600 images, loss=69.47379748487548 and correct%=0.77\n",
      "after 37700 images, loss=50.473830529093995 and correct%=0.89\n",
      "after 37800 images, loss=57.592838268645444 and correct%=0.85\n",
      "after 37900 images, loss=57.10139488754459 and correct%=0.88\n",
      "after 38000 images, loss=54.02447869690952 and correct%=0.89\n",
      "after 38100 images, loss=57.1708024217023 and correct%=0.86\n",
      "after 38200 images, loss=44.28636640354927 and correct%=0.92\n",
      "after 38300 images, loss=58.47484882059538 and correct%=0.83\n",
      "after 38400 images, loss=61.97975010131661 and correct%=0.83\n",
      "after 38500 images, loss=42.0575594221166 and correct%=0.92\n",
      "after 38600 images, loss=71.19926875745773 and correct%=0.83\n",
      "after 38700 images, loss=67.81934976541949 and correct%=0.79\n",
      "after 38800 images, loss=49.46318333710483 and correct%=0.9\n",
      "after 38900 images, loss=38.33073185115483 and correct%=0.93\n",
      "after 39000 images, loss=44.88239811934245 and correct%=0.89\n",
      "after 39100 images, loss=41.642319781402804 and correct%=0.91\n",
      "after 39200 images, loss=43.54151189201334 and correct%=0.93\n",
      "after 39300 images, loss=51.469663304963206 and correct%=0.9\n",
      "after 39400 images, loss=73.974066384383 and correct%=0.82\n",
      "after 39500 images, loss=71.58905516163787 and correct%=0.77\n",
      "after 39600 images, loss=56.3643671224513 and correct%=0.88\n",
      "after 39700 images, loss=55.07382262389806 and correct%=0.86\n",
      "after 39800 images, loss=65.52596937288182 and correct%=0.87\n",
      "after 39900 images, loss=61.79843797862171 and correct%=0.8\n",
      "after 40000 images, loss=63.859734246379475 and correct%=0.83\n",
      "after 40100 images, loss=52.40864285675669 and correct%=0.88\n",
      "after 40200 images, loss=48.027890732593285 and correct%=0.91\n",
      "after 40300 images, loss=52.44989938779693 and correct%=0.86\n",
      "after 40400 images, loss=44.806703310691724 and correct%=0.92\n",
      "after 40500 images, loss=61.43201058976104 and correct%=0.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 40600 images, loss=58.33109942251253 and correct%=0.88\n",
      "after 40700 images, loss=50.83892677763641 and correct%=0.88\n",
      "after 40800 images, loss=48.98101541325639 and correct%=0.92\n",
      "after 40900 images, loss=45.69614328412838 and correct%=0.9\n",
      "after 41000 images, loss=44.76801352090879 and correct%=0.91\n",
      "after 41100 images, loss=60.325640440064426 and correct%=0.84\n",
      "after 41200 images, loss=53.154674615515994 and correct%=0.85\n",
      "after 41300 images, loss=61.449842062569665 and correct%=0.84\n",
      "after 41400 images, loss=74.19612596618076 and correct%=0.84\n",
      "after 41500 images, loss=72.38345239269428 and correct%=0.81\n",
      "after 41600 images, loss=70.13338352725978 and correct%=0.81\n",
      "after 41700 images, loss=51.96430788566771 and correct%=0.89\n",
      "after 41800 images, loss=56.72145253985029 and correct%=0.87\n",
      "after 41900 images, loss=47.67154814457865 and correct%=0.92\n",
      "after 42000 images, loss=52.70447629007874 and correct%=0.88\n",
      "after 42100 images, loss=48.7920479226588 and correct%=0.88\n",
      "after 42200 images, loss=70.41857715828962 and correct%=0.81\n",
      "after 42300 images, loss=68.64999648529597 and correct%=0.82\n",
      "after 42400 images, loss=75.19317990469212 and correct%=0.84\n",
      "after 42500 images, loss=65.61603379348618 and correct%=0.85\n",
      "after 42600 images, loss=57.338205560278176 and correct%=0.87\n",
      "after 42700 images, loss=51.41395917460601 and correct%=0.88\n",
      "after 42800 images, loss=52.00528200638897 and correct%=0.9\n",
      "after 42900 images, loss=54.06649993196099 and correct%=0.86\n",
      "after 43000 images, loss=70.87548078337413 and correct%=0.78\n",
      "after 43100 images, loss=69.01612454567878 and correct%=0.79\n",
      "after 43200 images, loss=44.298917912081215 and correct%=0.92\n",
      "after 43300 images, loss=51.937488310549405 and correct%=0.89\n",
      "after 43400 images, loss=31.760649642682893 and correct%=0.96\n",
      "after 43500 images, loss=36.79297511183541 and correct%=0.94\n",
      "after 43600 images, loss=50.161344096434746 and correct%=0.82\n",
      "after 43700 images, loss=45.42950773079468 and correct%=0.93\n",
      "after 43800 images, loss=49.55189407360058 and correct%=0.88\n",
      "after 43900 images, loss=54.71377523221552 and correct%=0.86\n",
      "after 44000 images, loss=57.30242247577607 and correct%=0.83\n",
      "after 44100 images, loss=51.338977105180746 and correct%=0.85\n",
      "after 44200 images, loss=67.57382114747021 and correct%=0.83\n",
      "after 44300 images, loss=60.86125792191546 and correct%=0.87\n",
      "after 44400 images, loss=64.49288810007474 and correct%=0.84\n",
      "after 44500 images, loss=53.54732099827955 and correct%=0.86\n",
      "after 44600 images, loss=37.76802205661426 and correct%=0.92\n",
      "after 44700 images, loss=37.70316038638729 and correct%=0.91\n",
      "after 44800 images, loss=51.39429906395324 and correct%=0.88\n",
      "after 44900 images, loss=63.84367550829597 and correct%=0.84\n",
      "after 45000 images, loss=54.53620879745392 and correct%=0.83\n",
      "after 45100 images, loss=67.8766416065411 and correct%=0.83\n",
      "after 45200 images, loss=58.79177667248634 and correct%=0.84\n",
      "after 45300 images, loss=46.48376087374905 and correct%=0.88\n",
      "after 45400 images, loss=39.07600237599835 and correct%=0.93\n",
      "after 45500 images, loss=64.68772186373033 and correct%=0.83\n",
      "after 45600 images, loss=54.217046204537795 and correct%=0.88\n",
      "after 45700 images, loss=56.146840336513534 and correct%=0.84\n",
      "after 45800 images, loss=54.145392822336866 and correct%=0.86\n",
      "after 45900 images, loss=62.23650390038732 and correct%=0.87\n",
      "after 46000 images, loss=54.874792514635196 and correct%=0.87\n",
      "after 46100 images, loss=65.00860354592704 and correct%=0.83\n",
      "after 46200 images, loss=59.8056666893975 and correct%=0.88\n",
      "after 46300 images, loss=68.45590776184639 and correct%=0.83\n",
      "after 46400 images, loss=60.42251748335624 and correct%=0.85\n",
      "after 46500 images, loss=53.03810185728687 and correct%=0.85\n",
      "after 46600 images, loss=43.099439081242345 and correct%=0.93\n",
      "after 46700 images, loss=45.41894496192656 and correct%=0.89\n",
      "after 46800 images, loss=41.31995376568762 and correct%=0.89\n",
      "after 46900 images, loss=44.52093611577954 and correct%=0.87\n",
      "after 47000 images, loss=46.81013099913921 and correct%=0.87\n",
      "after 47100 images, loss=49.373394238388485 and correct%=0.87\n",
      "after 47200 images, loss=42.16435649163592 and correct%=0.92\n",
      "after 47300 images, loss=63.267169324423016 and correct%=0.83\n",
      "after 47400 images, loss=60.61096595468388 and correct%=0.85\n",
      "after 47500 images, loss=60.22070816109233 and correct%=0.86\n",
      "after 47600 images, loss=51.486039952087125 and correct%=0.91\n",
      "after 47700 images, loss=60.826408130731345 and correct%=0.81\n",
      "after 47800 images, loss=53.942274701925534 and correct%=0.88\n",
      "after 47900 images, loss=39.14822202957277 and correct%=0.92\n",
      "after 48000 images, loss=63.55936909243509 and correct%=0.81\n",
      "after 48100 images, loss=44.52206527648624 and correct%=0.91\n",
      "after 48200 images, loss=35.33076005591878 and correct%=0.91\n",
      "after 48300 images, loss=38.7850684565897 and correct%=0.91\n",
      "after 48400 images, loss=63.31850795200944 and correct%=0.85\n",
      "after 48500 images, loss=34.180196035804926 and correct%=0.93\n",
      "after 48600 images, loss=50.844737406218506 and correct%=0.86\n",
      "after 48700 images, loss=44.188241619748325 and correct%=0.94\n",
      "after 48800 images, loss=39.43269669496657 and correct%=0.9\n",
      "after 48900 images, loss=40.21374290534761 and correct%=0.94\n",
      "after 49000 images, loss=67.68253801405281 and correct%=0.82\n",
      "after 49100 images, loss=76.36659808278552 and correct%=0.82\n",
      "after 49200 images, loss=58.44250059953201 and correct%=0.77\n",
      "after 49300 images, loss=59.87412816732961 and correct%=0.82\n",
      "after 49400 images, loss=34.36153716708219 and correct%=0.91\n",
      "after 49500 images, loss=63.36971712317049 and correct%=0.75\n",
      "after 49600 images, loss=93.67107279677039 and correct%=0.69\n",
      "after 49700 images, loss=65.24099192299114 and correct%=0.84\n",
      "after 49800 images, loss=42.64822036538306 and correct%=0.92\n",
      "after 49900 images, loss=69.96030436576422 and correct%=0.85\n"
     ]
    }
   ],
   "source": [
    "# Now let's train\n",
    "\n",
    "model_test.train(train_set, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "framed-headset",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning",
   "language": "python",
   "name": "learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
